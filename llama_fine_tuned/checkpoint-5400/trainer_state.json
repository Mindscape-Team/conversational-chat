{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.9837651122625215,
  "eval_steps": 100,
  "global_step": 5400,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.005526770293609672,
      "grad_norm": 3.723069190979004,
      "learning_rate": 6.134969325153375e-07,
      "loss": 2.7524,
      "step": 10
    },
    {
      "epoch": 0.011053540587219343,
      "grad_norm": 8.244170188903809,
      "learning_rate": 1.8404907975460124e-06,
      "loss": 2.5531,
      "step": 20
    },
    {
      "epoch": 0.016580310880829015,
      "grad_norm": 7.248188495635986,
      "learning_rate": 3.0674846625766875e-06,
      "loss": 2.7102,
      "step": 30
    },
    {
      "epoch": 0.022107081174438686,
      "grad_norm": 4.0731706619262695,
      "learning_rate": 4.294478527607362e-06,
      "loss": 2.8253,
      "step": 40
    },
    {
      "epoch": 0.027633851468048358,
      "grad_norm": 6.066887378692627,
      "learning_rate": 5.521472392638038e-06,
      "loss": 2.3419,
      "step": 50
    },
    {
      "epoch": 0.03316062176165803,
      "grad_norm": 3.9817190170288086,
      "learning_rate": 6.748466257668712e-06,
      "loss": 2.3017,
      "step": 60
    },
    {
      "epoch": 0.0386873920552677,
      "grad_norm": 3.751540422439575,
      "learning_rate": 7.975460122699386e-06,
      "loss": 2.1257,
      "step": 70
    },
    {
      "epoch": 0.04421416234887737,
      "grad_norm": 6.1784257888793945,
      "learning_rate": 9.202453987730062e-06,
      "loss": 1.8182,
      "step": 80
    },
    {
      "epoch": 0.049740932642487044,
      "grad_norm": 0.9801164865493774,
      "learning_rate": 1.0429447852760737e-05,
      "loss": 1.4271,
      "step": 90
    },
    {
      "epoch": 0.055267702936096716,
      "grad_norm": 0.6667304635047913,
      "learning_rate": 1.1656441717791411e-05,
      "loss": 1.2782,
      "step": 100
    },
    {
      "epoch": 0.055267702936096716,
      "eval_loss": 1.2290273904800415,
      "eval_runtime": 431.495,
      "eval_samples_per_second": 3.729,
      "eval_steps_per_second": 0.468,
      "step": 100
    },
    {
      "epoch": 0.06079447322970639,
      "grad_norm": 0.6221052408218384,
      "learning_rate": 1.2883435582822085e-05,
      "loss": 1.2234,
      "step": 110
    },
    {
      "epoch": 0.06632124352331606,
      "grad_norm": 0.4443826973438263,
      "learning_rate": 1.4110429447852763e-05,
      "loss": 1.1954,
      "step": 120
    },
    {
      "epoch": 0.07184801381692574,
      "grad_norm": 0.48571866750717163,
      "learning_rate": 1.5337423312883436e-05,
      "loss": 1.1781,
      "step": 130
    },
    {
      "epoch": 0.0773747841105354,
      "grad_norm": 0.4583202302455902,
      "learning_rate": 1.656441717791411e-05,
      "loss": 1.0228,
      "step": 140
    },
    {
      "epoch": 0.08290155440414508,
      "grad_norm": 0.4818533658981323,
      "learning_rate": 1.7791411042944788e-05,
      "loss": 1.1349,
      "step": 150
    },
    {
      "epoch": 0.08842832469775475,
      "grad_norm": 0.4626677334308624,
      "learning_rate": 1.9018404907975462e-05,
      "loss": 1.1046,
      "step": 160
    },
    {
      "epoch": 0.09395509499136442,
      "grad_norm": 0.5646718144416809,
      "learning_rate": 1.9992401215805473e-05,
      "loss": 1.0355,
      "step": 170
    },
    {
      "epoch": 0.09948186528497409,
      "grad_norm": 0.5247638821601868,
      "learning_rate": 1.995440729483283e-05,
      "loss": 1.0769,
      "step": 180
    },
    {
      "epoch": 0.10500863557858377,
      "grad_norm": 0.6413401961326599,
      "learning_rate": 1.9916413373860184e-05,
      "loss": 1.0603,
      "step": 190
    },
    {
      "epoch": 0.11053540587219343,
      "grad_norm": 0.6030570268630981,
      "learning_rate": 1.9878419452887542e-05,
      "loss": 1.0084,
      "step": 200
    },
    {
      "epoch": 0.11053540587219343,
      "eval_loss": 1.0325943231582642,
      "eval_runtime": 392.3071,
      "eval_samples_per_second": 4.101,
      "eval_steps_per_second": 0.515,
      "step": 200
    },
    {
      "epoch": 0.11606217616580311,
      "grad_norm": 0.5852571129798889,
      "learning_rate": 1.9840425531914894e-05,
      "loss": 1.0492,
      "step": 210
    },
    {
      "epoch": 0.12158894645941278,
      "grad_norm": 0.610137403011322,
      "learning_rate": 1.980243161094225e-05,
      "loss": 1.0136,
      "step": 220
    },
    {
      "epoch": 0.12711571675302244,
      "grad_norm": 0.6231804490089417,
      "learning_rate": 1.9764437689969608e-05,
      "loss": 0.9777,
      "step": 230
    },
    {
      "epoch": 0.13264248704663212,
      "grad_norm": 0.6114420294761658,
      "learning_rate": 1.972644376899696e-05,
      "loss": 1.0016,
      "step": 240
    },
    {
      "epoch": 0.1381692573402418,
      "grad_norm": 0.6706142425537109,
      "learning_rate": 1.9688449848024318e-05,
      "loss": 0.9895,
      "step": 250
    },
    {
      "epoch": 0.14369602763385148,
      "grad_norm": 0.637876033782959,
      "learning_rate": 1.9650455927051673e-05,
      "loss": 1.008,
      "step": 260
    },
    {
      "epoch": 0.14922279792746113,
      "grad_norm": 0.7456838488578796,
      "learning_rate": 1.961246200607903e-05,
      "loss": 1.0058,
      "step": 270
    },
    {
      "epoch": 0.1547495682210708,
      "grad_norm": 0.5932880640029907,
      "learning_rate": 1.9574468085106384e-05,
      "loss": 0.9371,
      "step": 280
    },
    {
      "epoch": 0.16027633851468048,
      "grad_norm": 0.6662213206291199,
      "learning_rate": 1.9536474164133742e-05,
      "loss": 0.9954,
      "step": 290
    },
    {
      "epoch": 0.16580310880829016,
      "grad_norm": 0.8943974375724792,
      "learning_rate": 1.9498480243161094e-05,
      "loss": 0.9854,
      "step": 300
    },
    {
      "epoch": 0.16580310880829016,
      "eval_loss": 0.9952279329299927,
      "eval_runtime": 415.2909,
      "eval_samples_per_second": 3.874,
      "eval_steps_per_second": 0.486,
      "step": 300
    },
    {
      "epoch": 0.17132987910189984,
      "grad_norm": 0.7368950843811035,
      "learning_rate": 1.9460486322188453e-05,
      "loss": 0.951,
      "step": 310
    },
    {
      "epoch": 0.1768566493955095,
      "grad_norm": 0.7272067070007324,
      "learning_rate": 1.9422492401215808e-05,
      "loss": 0.9838,
      "step": 320
    },
    {
      "epoch": 0.18238341968911917,
      "grad_norm": 0.7351976633071899,
      "learning_rate": 1.9384498480243163e-05,
      "loss": 0.9758,
      "step": 330
    },
    {
      "epoch": 0.18791018998272885,
      "grad_norm": 0.6968951225280762,
      "learning_rate": 1.9346504559270518e-05,
      "loss": 0.9856,
      "step": 340
    },
    {
      "epoch": 0.19343696027633853,
      "grad_norm": 0.7588597536087036,
      "learning_rate": 1.9308510638297873e-05,
      "loss": 1.0276,
      "step": 350
    },
    {
      "epoch": 0.19896373056994818,
      "grad_norm": 0.6128564476966858,
      "learning_rate": 1.927051671732523e-05,
      "loss": 0.9551,
      "step": 360
    },
    {
      "epoch": 0.20449050086355786,
      "grad_norm": 0.756742000579834,
      "learning_rate": 1.9232522796352587e-05,
      "loss": 0.9154,
      "step": 370
    },
    {
      "epoch": 0.21001727115716753,
      "grad_norm": 0.8182570338249207,
      "learning_rate": 1.9194528875379942e-05,
      "loss": 1.0258,
      "step": 380
    },
    {
      "epoch": 0.2155440414507772,
      "grad_norm": 0.8528514504432678,
      "learning_rate": 1.9156534954407294e-05,
      "loss": 1.037,
      "step": 390
    },
    {
      "epoch": 0.22107081174438686,
      "grad_norm": 0.7432777285575867,
      "learning_rate": 1.9118541033434652e-05,
      "loss": 0.9312,
      "step": 400
    },
    {
      "epoch": 0.22107081174438686,
      "eval_loss": 0.9749093651771545,
      "eval_runtime": 405.9477,
      "eval_samples_per_second": 3.964,
      "eval_steps_per_second": 0.498,
      "step": 400
    },
    {
      "epoch": 0.22659758203799654,
      "grad_norm": 0.8561288118362427,
      "learning_rate": 1.9080547112462008e-05,
      "loss": 0.923,
      "step": 410
    },
    {
      "epoch": 0.23212435233160622,
      "grad_norm": 0.8074119091033936,
      "learning_rate": 1.9042553191489363e-05,
      "loss": 0.9678,
      "step": 420
    },
    {
      "epoch": 0.2376511226252159,
      "grad_norm": 0.7989829182624817,
      "learning_rate": 1.9004559270516718e-05,
      "loss": 0.9998,
      "step": 430
    },
    {
      "epoch": 0.24317789291882555,
      "grad_norm": 0.7512258887290955,
      "learning_rate": 1.8966565349544077e-05,
      "loss": 1.0334,
      "step": 440
    },
    {
      "epoch": 0.24870466321243523,
      "grad_norm": 0.8233409523963928,
      "learning_rate": 1.892857142857143e-05,
      "loss": 0.9842,
      "step": 450
    },
    {
      "epoch": 0.2542314335060449,
      "grad_norm": 0.8100282549858093,
      "learning_rate": 1.8890577507598787e-05,
      "loss": 0.9396,
      "step": 460
    },
    {
      "epoch": 0.2597582037996546,
      "grad_norm": 0.7395476698875427,
      "learning_rate": 1.8852583586626142e-05,
      "loss": 0.8963,
      "step": 470
    },
    {
      "epoch": 0.26528497409326424,
      "grad_norm": 0.941339373588562,
      "learning_rate": 1.8814589665653497e-05,
      "loss": 0.9848,
      "step": 480
    },
    {
      "epoch": 0.27081174438687394,
      "grad_norm": 0.7850469946861267,
      "learning_rate": 1.8776595744680852e-05,
      "loss": 0.8895,
      "step": 490
    },
    {
      "epoch": 0.2763385146804836,
      "grad_norm": 0.802154004573822,
      "learning_rate": 1.8738601823708208e-05,
      "loss": 0.937,
      "step": 500
    },
    {
      "epoch": 0.2763385146804836,
      "eval_loss": 0.9610368609428406,
      "eval_runtime": 405.7091,
      "eval_samples_per_second": 3.966,
      "eval_steps_per_second": 0.498,
      "step": 500
    },
    {
      "epoch": 0.28186528497409324,
      "grad_norm": 0.8186458349227905,
      "learning_rate": 1.8700607902735563e-05,
      "loss": 0.9882,
      "step": 510
    },
    {
      "epoch": 0.28739205526770295,
      "grad_norm": 0.8291501402854919,
      "learning_rate": 1.866261398176292e-05,
      "loss": 0.9336,
      "step": 520
    },
    {
      "epoch": 0.2929188255613126,
      "grad_norm": 0.8416099548339844,
      "learning_rate": 1.8624620060790277e-05,
      "loss": 0.9574,
      "step": 530
    },
    {
      "epoch": 0.29844559585492225,
      "grad_norm": 0.9065300822257996,
      "learning_rate": 1.8586626139817632e-05,
      "loss": 1.0349,
      "step": 540
    },
    {
      "epoch": 0.30397236614853196,
      "grad_norm": 0.792423665523529,
      "learning_rate": 1.8548632218844987e-05,
      "loss": 0.9604,
      "step": 550
    },
    {
      "epoch": 0.3094991364421416,
      "grad_norm": 0.9140130877494812,
      "learning_rate": 1.8510638297872342e-05,
      "loss": 0.9774,
      "step": 560
    },
    {
      "epoch": 0.3150259067357513,
      "grad_norm": 0.7893204092979431,
      "learning_rate": 1.8472644376899697e-05,
      "loss": 0.8924,
      "step": 570
    },
    {
      "epoch": 0.32055267702936097,
      "grad_norm": 0.8775556683540344,
      "learning_rate": 1.8434650455927052e-05,
      "loss": 0.9339,
      "step": 580
    },
    {
      "epoch": 0.3260794473229706,
      "grad_norm": 1.0101217031478882,
      "learning_rate": 1.8396656534954408e-05,
      "loss": 0.9766,
      "step": 590
    },
    {
      "epoch": 0.3316062176165803,
      "grad_norm": 0.7752426862716675,
      "learning_rate": 1.8358662613981763e-05,
      "loss": 0.9552,
      "step": 600
    },
    {
      "epoch": 0.3316062176165803,
      "eval_loss": 0.9506908655166626,
      "eval_runtime": 404.4612,
      "eval_samples_per_second": 3.978,
      "eval_steps_per_second": 0.499,
      "step": 600
    },
    {
      "epoch": 0.33713298791019,
      "grad_norm": 0.8887196779251099,
      "learning_rate": 1.832066869300912e-05,
      "loss": 0.9333,
      "step": 610
    },
    {
      "epoch": 0.3426597582037997,
      "grad_norm": 0.8313254714012146,
      "learning_rate": 1.8282674772036476e-05,
      "loss": 0.903,
      "step": 620
    },
    {
      "epoch": 0.34818652849740933,
      "grad_norm": 0.8366193175315857,
      "learning_rate": 1.824468085106383e-05,
      "loss": 0.9169,
      "step": 630
    },
    {
      "epoch": 0.353713298791019,
      "grad_norm": 0.9821773171424866,
      "learning_rate": 1.8206686930091187e-05,
      "loss": 0.9558,
      "step": 640
    },
    {
      "epoch": 0.3592400690846287,
      "grad_norm": 0.8635573983192444,
      "learning_rate": 1.8168693009118542e-05,
      "loss": 0.9113,
      "step": 650
    },
    {
      "epoch": 0.36476683937823834,
      "grad_norm": 0.9874703884124756,
      "learning_rate": 1.8130699088145897e-05,
      "loss": 0.8938,
      "step": 660
    },
    {
      "epoch": 0.370293609671848,
      "grad_norm": 1.0442866086959839,
      "learning_rate": 1.8092705167173256e-05,
      "loss": 0.942,
      "step": 670
    },
    {
      "epoch": 0.3758203799654577,
      "grad_norm": 1.0088356733322144,
      "learning_rate": 1.8054711246200608e-05,
      "loss": 0.9585,
      "step": 680
    },
    {
      "epoch": 0.38134715025906735,
      "grad_norm": 0.8545465469360352,
      "learning_rate": 1.8016717325227966e-05,
      "loss": 0.9109,
      "step": 690
    },
    {
      "epoch": 0.38687392055267705,
      "grad_norm": 0.9691437482833862,
      "learning_rate": 1.797872340425532e-05,
      "loss": 0.8978,
      "step": 700
    },
    {
      "epoch": 0.38687392055267705,
      "eval_loss": 0.9425151348114014,
      "eval_runtime": 408.3281,
      "eval_samples_per_second": 3.94,
      "eval_steps_per_second": 0.495,
      "step": 700
    },
    {
      "epoch": 0.3924006908462867,
      "grad_norm": 0.9547154307365417,
      "learning_rate": 1.7940729483282676e-05,
      "loss": 0.942,
      "step": 710
    },
    {
      "epoch": 0.39792746113989635,
      "grad_norm": 1.0505295991897583,
      "learning_rate": 1.790273556231003e-05,
      "loss": 0.9305,
      "step": 720
    },
    {
      "epoch": 0.40345423143350606,
      "grad_norm": 1.000160574913025,
      "learning_rate": 1.7864741641337387e-05,
      "loss": 0.9002,
      "step": 730
    },
    {
      "epoch": 0.4089810017271157,
      "grad_norm": 0.8729129433631897,
      "learning_rate": 1.7826747720364742e-05,
      "loss": 0.9296,
      "step": 740
    },
    {
      "epoch": 0.41450777202072536,
      "grad_norm": 0.9970493912696838,
      "learning_rate": 1.7788753799392097e-05,
      "loss": 0.946,
      "step": 750
    },
    {
      "epoch": 0.42003454231433507,
      "grad_norm": 0.8735694885253906,
      "learning_rate": 1.7750759878419456e-05,
      "loss": 0.9722,
      "step": 760
    },
    {
      "epoch": 0.4255613126079447,
      "grad_norm": 1.0142921209335327,
      "learning_rate": 1.7712765957446807e-05,
      "loss": 0.947,
      "step": 770
    },
    {
      "epoch": 0.4310880829015544,
      "grad_norm": 0.909099280834198,
      "learning_rate": 1.7674772036474166e-05,
      "loss": 0.94,
      "step": 780
    },
    {
      "epoch": 0.4366148531951641,
      "grad_norm": 0.8914812803268433,
      "learning_rate": 1.763677811550152e-05,
      "loss": 0.9881,
      "step": 790
    },
    {
      "epoch": 0.4421416234887737,
      "grad_norm": 1.0168424844741821,
      "learning_rate": 1.7598784194528876e-05,
      "loss": 0.8713,
      "step": 800
    },
    {
      "epoch": 0.4421416234887737,
      "eval_loss": 0.9356987476348877,
      "eval_runtime": 407.1704,
      "eval_samples_per_second": 3.952,
      "eval_steps_per_second": 0.496,
      "step": 800
    },
    {
      "epoch": 0.44766839378238343,
      "grad_norm": 1.115212321281433,
      "learning_rate": 1.756079027355623e-05,
      "loss": 0.9089,
      "step": 810
    },
    {
      "epoch": 0.4531951640759931,
      "grad_norm": 0.9434346556663513,
      "learning_rate": 1.752279635258359e-05,
      "loss": 0.9035,
      "step": 820
    },
    {
      "epoch": 0.4587219343696028,
      "grad_norm": 0.9070565700531006,
      "learning_rate": 1.7484802431610942e-05,
      "loss": 0.899,
      "step": 830
    },
    {
      "epoch": 0.46424870466321244,
      "grad_norm": 1.0126855373382568,
      "learning_rate": 1.74468085106383e-05,
      "loss": 0.8762,
      "step": 840
    },
    {
      "epoch": 0.4697754749568221,
      "grad_norm": 1.1068205833435059,
      "learning_rate": 1.7408814589665656e-05,
      "loss": 0.8885,
      "step": 850
    },
    {
      "epoch": 0.4753022452504318,
      "grad_norm": 1.0521047115325928,
      "learning_rate": 1.737082066869301e-05,
      "loss": 0.9031,
      "step": 860
    },
    {
      "epoch": 0.48082901554404145,
      "grad_norm": 0.8957653045654297,
      "learning_rate": 1.7332826747720366e-05,
      "loss": 0.8834,
      "step": 870
    },
    {
      "epoch": 0.4863557858376511,
      "grad_norm": 0.9660986661911011,
      "learning_rate": 1.729483282674772e-05,
      "loss": 0.9287,
      "step": 880
    },
    {
      "epoch": 0.4918825561312608,
      "grad_norm": 0.944589376449585,
      "learning_rate": 1.7256838905775076e-05,
      "loss": 0.9086,
      "step": 890
    },
    {
      "epoch": 0.49740932642487046,
      "grad_norm": 0.9676238298416138,
      "learning_rate": 1.721884498480243e-05,
      "loss": 0.8877,
      "step": 900
    },
    {
      "epoch": 0.49740932642487046,
      "eval_loss": 0.9293144345283508,
      "eval_runtime": 406.8743,
      "eval_samples_per_second": 3.955,
      "eval_steps_per_second": 0.496,
      "step": 900
    },
    {
      "epoch": 0.5029360967184802,
      "grad_norm": 1.0717650651931763,
      "learning_rate": 1.718085106382979e-05,
      "loss": 0.9012,
      "step": 910
    },
    {
      "epoch": 0.5084628670120898,
      "grad_norm": 1.210530161857605,
      "learning_rate": 1.7142857142857142e-05,
      "loss": 0.9146,
      "step": 920
    },
    {
      "epoch": 0.5139896373056995,
      "grad_norm": 1.2071021795272827,
      "learning_rate": 1.71048632218845e-05,
      "loss": 0.9377,
      "step": 930
    },
    {
      "epoch": 0.5195164075993092,
      "grad_norm": 0.9941042065620422,
      "learning_rate": 1.7066869300911856e-05,
      "loss": 0.9346,
      "step": 940
    },
    {
      "epoch": 0.5250431778929189,
      "grad_norm": 1.1183199882507324,
      "learning_rate": 1.702887537993921e-05,
      "loss": 0.9635,
      "step": 950
    },
    {
      "epoch": 0.5305699481865285,
      "grad_norm": 1.0009732246398926,
      "learning_rate": 1.6990881458966566e-05,
      "loss": 0.9407,
      "step": 960
    },
    {
      "epoch": 0.5360967184801382,
      "grad_norm": 1.0777103900909424,
      "learning_rate": 1.6952887537993924e-05,
      "loss": 0.8905,
      "step": 970
    },
    {
      "epoch": 0.5416234887737479,
      "grad_norm": 1.1225868463516235,
      "learning_rate": 1.6914893617021276e-05,
      "loss": 0.9147,
      "step": 980
    },
    {
      "epoch": 0.5471502590673575,
      "grad_norm": 0.8849082589149475,
      "learning_rate": 1.6876899696048635e-05,
      "loss": 0.9108,
      "step": 990
    },
    {
      "epoch": 0.5526770293609672,
      "grad_norm": 1.0192471742630005,
      "learning_rate": 1.683890577507599e-05,
      "loss": 0.9,
      "step": 1000
    },
    {
      "epoch": 0.5526770293609672,
      "eval_loss": 0.9245635867118835,
      "eval_runtime": 391.7558,
      "eval_samples_per_second": 4.107,
      "eval_steps_per_second": 0.516,
      "step": 1000
    },
    {
      "epoch": 0.5582037996545769,
      "grad_norm": 1.1434139013290405,
      "learning_rate": 1.6800911854103345e-05,
      "loss": 0.898,
      "step": 1010
    },
    {
      "epoch": 0.5637305699481865,
      "grad_norm": 1.0194205045700073,
      "learning_rate": 1.67629179331307e-05,
      "loss": 0.9169,
      "step": 1020
    },
    {
      "epoch": 0.5692573402417962,
      "grad_norm": 0.9614776372909546,
      "learning_rate": 1.6724924012158056e-05,
      "loss": 0.8258,
      "step": 1030
    },
    {
      "epoch": 0.5747841105354059,
      "grad_norm": 1.0995752811431885,
      "learning_rate": 1.668693009118541e-05,
      "loss": 0.8361,
      "step": 1040
    },
    {
      "epoch": 0.5803108808290155,
      "grad_norm": 0.9262009859085083,
      "learning_rate": 1.664893617021277e-05,
      "loss": 0.9188,
      "step": 1050
    },
    {
      "epoch": 0.5858376511226252,
      "grad_norm": 0.9923626780509949,
      "learning_rate": 1.6610942249240124e-05,
      "loss": 0.9711,
      "step": 1060
    },
    {
      "epoch": 0.5913644214162349,
      "grad_norm": 1.1009814739227295,
      "learning_rate": 1.6572948328267476e-05,
      "loss": 0.8939,
      "step": 1070
    },
    {
      "epoch": 0.5968911917098445,
      "grad_norm": 1.0646668672561646,
      "learning_rate": 1.6534954407294835e-05,
      "loss": 0.9354,
      "step": 1080
    },
    {
      "epoch": 0.6024179620034542,
      "grad_norm": 1.0520495176315308,
      "learning_rate": 1.649696048632219e-05,
      "loss": 0.876,
      "step": 1090
    },
    {
      "epoch": 0.6079447322970639,
      "grad_norm": 1.0422852039337158,
      "learning_rate": 1.6458966565349545e-05,
      "loss": 0.9366,
      "step": 1100
    },
    {
      "epoch": 0.6079447322970639,
      "eval_loss": 0.9192306399345398,
      "eval_runtime": 389.7854,
      "eval_samples_per_second": 4.128,
      "eval_steps_per_second": 0.518,
      "step": 1100
    },
    {
      "epoch": 0.6134715025906736,
      "grad_norm": 1.0273290872573853,
      "learning_rate": 1.64209726443769e-05,
      "loss": 0.9018,
      "step": 1110
    },
    {
      "epoch": 0.6189982728842832,
      "grad_norm": 1.073481559753418,
      "learning_rate": 1.6382978723404255e-05,
      "loss": 0.8646,
      "step": 1120
    },
    {
      "epoch": 0.6245250431778929,
      "grad_norm": 1.0786257982254028,
      "learning_rate": 1.634498480243161e-05,
      "loss": 0.8428,
      "step": 1130
    },
    {
      "epoch": 0.6300518134715026,
      "grad_norm": 1.2220906019210815,
      "learning_rate": 1.630699088145897e-05,
      "loss": 0.9038,
      "step": 1140
    },
    {
      "epoch": 0.6355785837651122,
      "grad_norm": 1.1923216581344604,
      "learning_rate": 1.6268996960486324e-05,
      "loss": 0.9076,
      "step": 1150
    },
    {
      "epoch": 0.6411053540587219,
      "grad_norm": 1.1412622928619385,
      "learning_rate": 1.623100303951368e-05,
      "loss": 0.9327,
      "step": 1160
    },
    {
      "epoch": 0.6466321243523316,
      "grad_norm": 0.9570781588554382,
      "learning_rate": 1.6193009118541035e-05,
      "loss": 0.9001,
      "step": 1170
    },
    {
      "epoch": 0.6521588946459412,
      "grad_norm": 1.0366601943969727,
      "learning_rate": 1.615501519756839e-05,
      "loss": 0.8756,
      "step": 1180
    },
    {
      "epoch": 0.6576856649395509,
      "grad_norm": 0.9891634583473206,
      "learning_rate": 1.6117021276595745e-05,
      "loss": 0.9369,
      "step": 1190
    },
    {
      "epoch": 0.6632124352331606,
      "grad_norm": 1.0505485534667969,
      "learning_rate": 1.6079027355623104e-05,
      "loss": 0.9259,
      "step": 1200
    },
    {
      "epoch": 0.6632124352331606,
      "eval_loss": 0.9151798486709595,
      "eval_runtime": 388.6448,
      "eval_samples_per_second": 4.14,
      "eval_steps_per_second": 0.52,
      "step": 1200
    },
    {
      "epoch": 0.6687392055267702,
      "grad_norm": 1.152434229850769,
      "learning_rate": 1.6041033434650455e-05,
      "loss": 0.9036,
      "step": 1210
    },
    {
      "epoch": 0.67426597582038,
      "grad_norm": 1.0547147989273071,
      "learning_rate": 1.6003039513677814e-05,
      "loss": 0.8837,
      "step": 1220
    },
    {
      "epoch": 0.6797927461139897,
      "grad_norm": 1.1286817789077759,
      "learning_rate": 1.596504559270517e-05,
      "loss": 0.8646,
      "step": 1230
    },
    {
      "epoch": 0.6853195164075994,
      "grad_norm": 1.2008323669433594,
      "learning_rate": 1.5927051671732524e-05,
      "loss": 0.9328,
      "step": 1240
    },
    {
      "epoch": 0.690846286701209,
      "grad_norm": 1.2352581024169922,
      "learning_rate": 1.588905775075988e-05,
      "loss": 0.9084,
      "step": 1250
    },
    {
      "epoch": 0.6963730569948187,
      "grad_norm": 1.065269112586975,
      "learning_rate": 1.5851063829787235e-05,
      "loss": 0.9181,
      "step": 1260
    },
    {
      "epoch": 0.7018998272884284,
      "grad_norm": 1.0068895816802979,
      "learning_rate": 1.581306990881459e-05,
      "loss": 0.9566,
      "step": 1270
    },
    {
      "epoch": 0.707426597582038,
      "grad_norm": 1.1468089818954468,
      "learning_rate": 1.5775075987841945e-05,
      "loss": 0.9287,
      "step": 1280
    },
    {
      "epoch": 0.7129533678756477,
      "grad_norm": 1.202227234840393,
      "learning_rate": 1.5737082066869304e-05,
      "loss": 0.9087,
      "step": 1290
    },
    {
      "epoch": 0.7184801381692574,
      "grad_norm": 1.0840487480163574,
      "learning_rate": 1.569908814589666e-05,
      "loss": 0.8353,
      "step": 1300
    },
    {
      "epoch": 0.7184801381692574,
      "eval_loss": 0.9115446209907532,
      "eval_runtime": 389.8365,
      "eval_samples_per_second": 4.127,
      "eval_steps_per_second": 0.518,
      "step": 1300
    },
    {
      "epoch": 0.724006908462867,
      "grad_norm": 1.11477530002594,
      "learning_rate": 1.5661094224924014e-05,
      "loss": 0.9361,
      "step": 1310
    },
    {
      "epoch": 0.7295336787564767,
      "grad_norm": 1.085260033607483,
      "learning_rate": 1.562310030395137e-05,
      "loss": 0.8609,
      "step": 1320
    },
    {
      "epoch": 0.7350604490500864,
      "grad_norm": 1.108992099761963,
      "learning_rate": 1.5585106382978724e-05,
      "loss": 0.9509,
      "step": 1330
    },
    {
      "epoch": 0.740587219343696,
      "grad_norm": 1.046456217765808,
      "learning_rate": 1.554711246200608e-05,
      "loss": 0.8649,
      "step": 1340
    },
    {
      "epoch": 0.7461139896373057,
      "grad_norm": 1.1379836797714233,
      "learning_rate": 1.5509118541033438e-05,
      "loss": 0.9321,
      "step": 1350
    },
    {
      "epoch": 0.7516407599309154,
      "grad_norm": 1.125759243965149,
      "learning_rate": 1.547112462006079e-05,
      "loss": 0.8753,
      "step": 1360
    },
    {
      "epoch": 0.7571675302245251,
      "grad_norm": 1.0888633728027344,
      "learning_rate": 1.543313069908815e-05,
      "loss": 0.8827,
      "step": 1370
    },
    {
      "epoch": 0.7626943005181347,
      "grad_norm": 1.1972472667694092,
      "learning_rate": 1.5395136778115504e-05,
      "loss": 0.9028,
      "step": 1380
    },
    {
      "epoch": 0.7682210708117444,
      "grad_norm": 0.9866268038749695,
      "learning_rate": 1.535714285714286e-05,
      "loss": 0.8348,
      "step": 1390
    },
    {
      "epoch": 0.7737478411053541,
      "grad_norm": 1.2097495794296265,
      "learning_rate": 1.5319148936170214e-05,
      "loss": 0.9394,
      "step": 1400
    },
    {
      "epoch": 0.7737478411053541,
      "eval_loss": 0.9079686999320984,
      "eval_runtime": 392.0037,
      "eval_samples_per_second": 4.105,
      "eval_steps_per_second": 0.515,
      "step": 1400
    },
    {
      "epoch": 0.7792746113989637,
      "grad_norm": 1.1841257810592651,
      "learning_rate": 1.528115501519757e-05,
      "loss": 0.8336,
      "step": 1410
    },
    {
      "epoch": 0.7848013816925734,
      "grad_norm": 1.0546866655349731,
      "learning_rate": 1.5243161094224926e-05,
      "loss": 0.9095,
      "step": 1420
    },
    {
      "epoch": 0.7903281519861831,
      "grad_norm": 1.2017275094985962,
      "learning_rate": 1.520516717325228e-05,
      "loss": 0.925,
      "step": 1430
    },
    {
      "epoch": 0.7958549222797927,
      "grad_norm": 1.1299337148666382,
      "learning_rate": 1.5167173252279636e-05,
      "loss": 0.9438,
      "step": 1440
    },
    {
      "epoch": 0.8013816925734024,
      "grad_norm": 1.133646011352539,
      "learning_rate": 1.5129179331306991e-05,
      "loss": 0.9095,
      "step": 1450
    },
    {
      "epoch": 0.8069084628670121,
      "grad_norm": 1.0846583843231201,
      "learning_rate": 1.5091185410334348e-05,
      "loss": 0.9106,
      "step": 1460
    },
    {
      "epoch": 0.8124352331606217,
      "grad_norm": 1.0716532468795776,
      "learning_rate": 1.5053191489361702e-05,
      "loss": 0.8733,
      "step": 1470
    },
    {
      "epoch": 0.8179620034542314,
      "grad_norm": 1.190480351448059,
      "learning_rate": 1.5015197568389059e-05,
      "loss": 0.9586,
      "step": 1480
    },
    {
      "epoch": 0.8234887737478411,
      "grad_norm": 1.1699665784835815,
      "learning_rate": 1.4977203647416414e-05,
      "loss": 0.9259,
      "step": 1490
    },
    {
      "epoch": 0.8290155440414507,
      "grad_norm": 1.3336079120635986,
      "learning_rate": 1.493920972644377e-05,
      "loss": 0.9473,
      "step": 1500
    },
    {
      "epoch": 0.8290155440414507,
      "eval_loss": 0.9043383002281189,
      "eval_runtime": 393.7555,
      "eval_samples_per_second": 4.086,
      "eval_steps_per_second": 0.513,
      "step": 1500
    },
    {
      "epoch": 0.8345423143350604,
      "grad_norm": 1.0581562519073486,
      "learning_rate": 1.4901215805471126e-05,
      "loss": 0.8844,
      "step": 1510
    },
    {
      "epoch": 0.8400690846286701,
      "grad_norm": 1.1315557956695557,
      "learning_rate": 1.4863221884498483e-05,
      "loss": 0.8746,
      "step": 1520
    },
    {
      "epoch": 0.8455958549222798,
      "grad_norm": 1.1464297771453857,
      "learning_rate": 1.4825227963525836e-05,
      "loss": 0.9331,
      "step": 1530
    },
    {
      "epoch": 0.8511226252158894,
      "grad_norm": 1.24326753616333,
      "learning_rate": 1.4787234042553193e-05,
      "loss": 0.9182,
      "step": 1540
    },
    {
      "epoch": 0.8566493955094991,
      "grad_norm": 1.2595850229263306,
      "learning_rate": 1.4749240121580548e-05,
      "loss": 0.9562,
      "step": 1550
    },
    {
      "epoch": 0.8621761658031089,
      "grad_norm": 1.1955211162567139,
      "learning_rate": 1.4711246200607905e-05,
      "loss": 0.9347,
      "step": 1560
    },
    {
      "epoch": 0.8677029360967184,
      "grad_norm": 1.1327433586120605,
      "learning_rate": 1.4673252279635259e-05,
      "loss": 0.8484,
      "step": 1570
    },
    {
      "epoch": 0.8732297063903282,
      "grad_norm": 1.128312587738037,
      "learning_rate": 1.4635258358662615e-05,
      "loss": 0.8352,
      "step": 1580
    },
    {
      "epoch": 0.8787564766839379,
      "grad_norm": 1.6596239805221558,
      "learning_rate": 1.459726443768997e-05,
      "loss": 0.8896,
      "step": 1590
    },
    {
      "epoch": 0.8842832469775475,
      "grad_norm": 1.072384238243103,
      "learning_rate": 1.4559270516717326e-05,
      "loss": 0.9316,
      "step": 1600
    },
    {
      "epoch": 0.8842832469775475,
      "eval_loss": 0.9016879796981812,
      "eval_runtime": 393.604,
      "eval_samples_per_second": 4.088,
      "eval_steps_per_second": 0.513,
      "step": 1600
    },
    {
      "epoch": 0.8898100172711572,
      "grad_norm": 1.0414329767227173,
      "learning_rate": 1.4521276595744683e-05,
      "loss": 0.8915,
      "step": 1610
    },
    {
      "epoch": 0.8953367875647669,
      "grad_norm": 1.1765494346618652,
      "learning_rate": 1.4483282674772036e-05,
      "loss": 0.9323,
      "step": 1620
    },
    {
      "epoch": 0.9008635578583765,
      "grad_norm": 1.300842046737671,
      "learning_rate": 1.4445288753799393e-05,
      "loss": 0.8989,
      "step": 1630
    },
    {
      "epoch": 0.9063903281519862,
      "grad_norm": 1.2055058479309082,
      "learning_rate": 1.4407294832826748e-05,
      "loss": 0.9226,
      "step": 1640
    },
    {
      "epoch": 0.9119170984455959,
      "grad_norm": 1.2461390495300293,
      "learning_rate": 1.4369300911854105e-05,
      "loss": 0.8423,
      "step": 1650
    },
    {
      "epoch": 0.9174438687392056,
      "grad_norm": 1.34427011013031,
      "learning_rate": 1.433130699088146e-05,
      "loss": 0.8818,
      "step": 1660
    },
    {
      "epoch": 0.9229706390328152,
      "grad_norm": 1.1823104619979858,
      "learning_rate": 1.4293313069908817e-05,
      "loss": 0.9212,
      "step": 1670
    },
    {
      "epoch": 0.9284974093264249,
      "grad_norm": 1.1160506010055542,
      "learning_rate": 1.425531914893617e-05,
      "loss": 0.8895,
      "step": 1680
    },
    {
      "epoch": 0.9340241796200346,
      "grad_norm": 1.2820497751235962,
      "learning_rate": 1.4217325227963527e-05,
      "loss": 0.9135,
      "step": 1690
    },
    {
      "epoch": 0.9395509499136442,
      "grad_norm": 1.2309623956680298,
      "learning_rate": 1.4179331306990883e-05,
      "loss": 0.8506,
      "step": 1700
    },
    {
      "epoch": 0.9395509499136442,
      "eval_loss": 0.8990833759307861,
      "eval_runtime": 397.465,
      "eval_samples_per_second": 4.048,
      "eval_steps_per_second": 0.508,
      "step": 1700
    },
    {
      "epoch": 0.9450777202072539,
      "grad_norm": 1.129219889640808,
      "learning_rate": 1.414133738601824e-05,
      "loss": 0.8805,
      "step": 1710
    },
    {
      "epoch": 0.9506044905008636,
      "grad_norm": 1.1014457941055298,
      "learning_rate": 1.4103343465045593e-05,
      "loss": 0.8259,
      "step": 1720
    },
    {
      "epoch": 0.9561312607944732,
      "grad_norm": 1.1654518842697144,
      "learning_rate": 1.406534954407295e-05,
      "loss": 0.9099,
      "step": 1730
    },
    {
      "epoch": 0.9616580310880829,
      "grad_norm": 1.2649801969528198,
      "learning_rate": 1.4027355623100305e-05,
      "loss": 0.8718,
      "step": 1740
    },
    {
      "epoch": 0.9671848013816926,
      "grad_norm": 1.0861831903457642,
      "learning_rate": 1.3989361702127662e-05,
      "loss": 0.8566,
      "step": 1750
    },
    {
      "epoch": 0.9727115716753022,
      "grad_norm": 1.3210301399230957,
      "learning_rate": 1.3951367781155017e-05,
      "loss": 0.9158,
      "step": 1760
    },
    {
      "epoch": 0.9782383419689119,
      "grad_norm": 1.2364612817764282,
      "learning_rate": 1.391337386018237e-05,
      "loss": 0.8715,
      "step": 1770
    },
    {
      "epoch": 0.9837651122625216,
      "grad_norm": 1.1907358169555664,
      "learning_rate": 1.3875379939209727e-05,
      "loss": 0.9314,
      "step": 1780
    },
    {
      "epoch": 0.9892918825561312,
      "grad_norm": 1.0952712297439575,
      "learning_rate": 1.3837386018237083e-05,
      "loss": 0.8796,
      "step": 1790
    },
    {
      "epoch": 0.9948186528497409,
      "grad_norm": 1.09054434299469,
      "learning_rate": 1.379939209726444e-05,
      "loss": 0.8872,
      "step": 1800
    },
    {
      "epoch": 0.9948186528497409,
      "eval_loss": 0.8963317275047302,
      "eval_runtime": 399.1225,
      "eval_samples_per_second": 4.031,
      "eval_steps_per_second": 0.506,
      "step": 1800
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.2117226123809814,
      "learning_rate": 1.3761398176291793e-05,
      "loss": 0.8383,
      "step": 1810
    },
    {
      "epoch": 1.0055267702936097,
      "grad_norm": 1.1398522853851318,
      "learning_rate": 1.372340425531915e-05,
      "loss": 0.9309,
      "step": 1820
    },
    {
      "epoch": 1.0110535405872194,
      "grad_norm": 1.186449646949768,
      "learning_rate": 1.3685410334346505e-05,
      "loss": 0.8611,
      "step": 1830
    },
    {
      "epoch": 1.0165803108808291,
      "grad_norm": 1.3007580041885376,
      "learning_rate": 1.3647416413373862e-05,
      "loss": 0.9039,
      "step": 1840
    },
    {
      "epoch": 1.0221070811744386,
      "grad_norm": 1.4077868461608887,
      "learning_rate": 1.3609422492401217e-05,
      "loss": 0.9003,
      "step": 1850
    },
    {
      "epoch": 1.0276338514680483,
      "grad_norm": 1.144783616065979,
      "learning_rate": 1.3571428571428574e-05,
      "loss": 0.873,
      "step": 1860
    },
    {
      "epoch": 1.033160621761658,
      "grad_norm": 1.2291507720947266,
      "learning_rate": 1.3533434650455927e-05,
      "loss": 0.9238,
      "step": 1870
    },
    {
      "epoch": 1.0386873920552677,
      "grad_norm": 1.186647653579712,
      "learning_rate": 1.3495440729483284e-05,
      "loss": 0.8537,
      "step": 1880
    },
    {
      "epoch": 1.0442141623488774,
      "grad_norm": 1.2428827285766602,
      "learning_rate": 1.345744680851064e-05,
      "loss": 0.8563,
      "step": 1890
    },
    {
      "epoch": 1.0497409326424871,
      "grad_norm": 1.2961984872817993,
      "learning_rate": 1.3419452887537996e-05,
      "loss": 0.9178,
      "step": 1900
    },
    {
      "epoch": 1.0497409326424871,
      "eval_loss": 0.8941695094108582,
      "eval_runtime": 399.9862,
      "eval_samples_per_second": 4.023,
      "eval_steps_per_second": 0.505,
      "step": 1900
    },
    {
      "epoch": 1.0552677029360966,
      "grad_norm": 1.1323741674423218,
      "learning_rate": 1.338145896656535e-05,
      "loss": 0.8629,
      "step": 1910
    },
    {
      "epoch": 1.0607944732297063,
      "grad_norm": 1.3115429878234863,
      "learning_rate": 1.3343465045592707e-05,
      "loss": 0.8508,
      "step": 1920
    },
    {
      "epoch": 1.066321243523316,
      "grad_norm": 1.389632225036621,
      "learning_rate": 1.3305471124620062e-05,
      "loss": 0.9004,
      "step": 1930
    },
    {
      "epoch": 1.0718480138169257,
      "grad_norm": 1.2368775606155396,
      "learning_rate": 1.3267477203647417e-05,
      "loss": 0.8527,
      "step": 1940
    },
    {
      "epoch": 1.0773747841105354,
      "grad_norm": 1.230469822883606,
      "learning_rate": 1.3229483282674774e-05,
      "loss": 0.8387,
      "step": 1950
    },
    {
      "epoch": 1.0829015544041452,
      "grad_norm": 1.2770295143127441,
      "learning_rate": 1.3191489361702127e-05,
      "loss": 0.8899,
      "step": 1960
    },
    {
      "epoch": 1.0884283246977549,
      "grad_norm": 1.2669720649719238,
      "learning_rate": 1.3153495440729484e-05,
      "loss": 0.8643,
      "step": 1970
    },
    {
      "epoch": 1.0939550949913643,
      "grad_norm": 1.514715313911438,
      "learning_rate": 1.311550151975684e-05,
      "loss": 0.8691,
      "step": 1980
    },
    {
      "epoch": 1.099481865284974,
      "grad_norm": 1.3857756853103638,
      "learning_rate": 1.3077507598784196e-05,
      "loss": 0.8822,
      "step": 1990
    },
    {
      "epoch": 1.1050086355785838,
      "grad_norm": 1.1328387260437012,
      "learning_rate": 1.303951367781155e-05,
      "loss": 0.9311,
      "step": 2000
    },
    {
      "epoch": 1.1050086355785838,
      "eval_loss": 0.8922927379608154,
      "eval_runtime": 401.9032,
      "eval_samples_per_second": 4.003,
      "eval_steps_per_second": 0.503,
      "step": 2000
    },
    {
      "epoch": 1.1105354058721935,
      "grad_norm": 1.491133689880371,
      "learning_rate": 1.3001519756838907e-05,
      "loss": 0.941,
      "step": 2010
    },
    {
      "epoch": 1.1160621761658032,
      "grad_norm": 1.4316201210021973,
      "learning_rate": 1.2963525835866262e-05,
      "loss": 0.8643,
      "step": 2020
    },
    {
      "epoch": 1.1215889464594129,
      "grad_norm": 1.493514060974121,
      "learning_rate": 1.2925531914893619e-05,
      "loss": 0.8157,
      "step": 2030
    },
    {
      "epoch": 1.1271157167530224,
      "grad_norm": 1.2903321981430054,
      "learning_rate": 1.2887537993920974e-05,
      "loss": 0.8953,
      "step": 2040
    },
    {
      "epoch": 1.132642487046632,
      "grad_norm": 1.2861589193344116,
      "learning_rate": 1.284954407294833e-05,
      "loss": 0.8591,
      "step": 2050
    },
    {
      "epoch": 1.1381692573402418,
      "grad_norm": 1.1702686548233032,
      "learning_rate": 1.2811550151975684e-05,
      "loss": 0.9487,
      "step": 2060
    },
    {
      "epoch": 1.1436960276338515,
      "grad_norm": 1.3363311290740967,
      "learning_rate": 1.2773556231003041e-05,
      "loss": 0.8847,
      "step": 2070
    },
    {
      "epoch": 1.1492227979274612,
      "grad_norm": 1.178852915763855,
      "learning_rate": 1.2735562310030396e-05,
      "loss": 0.8654,
      "step": 2080
    },
    {
      "epoch": 1.1547495682210709,
      "grad_norm": 1.20868980884552,
      "learning_rate": 1.2697568389057753e-05,
      "loss": 0.8282,
      "step": 2090
    },
    {
      "epoch": 1.1602763385146804,
      "grad_norm": 1.1654052734375,
      "learning_rate": 1.2659574468085108e-05,
      "loss": 0.8691,
      "step": 2100
    },
    {
      "epoch": 1.1602763385146804,
      "eval_loss": 0.8908287286758423,
      "eval_runtime": 404.4918,
      "eval_samples_per_second": 3.978,
      "eval_steps_per_second": 0.499,
      "step": 2100
    },
    {
      "epoch": 1.16580310880829,
      "grad_norm": 1.0958136320114136,
      "learning_rate": 1.2621580547112462e-05,
      "loss": 0.8368,
      "step": 2110
    },
    {
      "epoch": 1.1713298791018998,
      "grad_norm": 1.1097280979156494,
      "learning_rate": 1.2583586626139819e-05,
      "loss": 0.826,
      "step": 2120
    },
    {
      "epoch": 1.1768566493955095,
      "grad_norm": 1.5207016468048096,
      "learning_rate": 1.2545592705167174e-05,
      "loss": 0.899,
      "step": 2130
    },
    {
      "epoch": 1.1823834196891192,
      "grad_norm": 1.1806669235229492,
      "learning_rate": 1.250759878419453e-05,
      "loss": 0.8779,
      "step": 2140
    },
    {
      "epoch": 1.187910189982729,
      "grad_norm": 1.3095998764038086,
      "learning_rate": 1.2469604863221884e-05,
      "loss": 0.9555,
      "step": 2150
    },
    {
      "epoch": 1.1934369602763386,
      "grad_norm": 1.3275408744812012,
      "learning_rate": 1.2431610942249241e-05,
      "loss": 0.8581,
      "step": 2160
    },
    {
      "epoch": 1.198963730569948,
      "grad_norm": 1.2701373100280762,
      "learning_rate": 1.2393617021276596e-05,
      "loss": 0.8829,
      "step": 2170
    },
    {
      "epoch": 1.2044905008635578,
      "grad_norm": 1.4035389423370361,
      "learning_rate": 1.2355623100303953e-05,
      "loss": 0.8477,
      "step": 2180
    },
    {
      "epoch": 1.2100172711571675,
      "grad_norm": 1.428413987159729,
      "learning_rate": 1.2317629179331308e-05,
      "loss": 0.93,
      "step": 2190
    },
    {
      "epoch": 1.2155440414507772,
      "grad_norm": 1.3022068738937378,
      "learning_rate": 1.2279635258358665e-05,
      "loss": 0.8547,
      "step": 2200
    },
    {
      "epoch": 1.2155440414507772,
      "eval_loss": 0.8879594206809998,
      "eval_runtime": 404.262,
      "eval_samples_per_second": 3.98,
      "eval_steps_per_second": 0.5,
      "step": 2200
    },
    {
      "epoch": 1.221070811744387,
      "grad_norm": 1.2094637155532837,
      "learning_rate": 1.2241641337386018e-05,
      "loss": 0.8877,
      "step": 2210
    },
    {
      "epoch": 1.2265975820379966,
      "grad_norm": 1.3550547361373901,
      "learning_rate": 1.2203647416413375e-05,
      "loss": 0.8785,
      "step": 2220
    },
    {
      "epoch": 1.2321243523316063,
      "grad_norm": 1.155469536781311,
      "learning_rate": 1.216565349544073e-05,
      "loss": 0.8358,
      "step": 2230
    },
    {
      "epoch": 1.2376511226252158,
      "grad_norm": 1.4513344764709473,
      "learning_rate": 1.2127659574468087e-05,
      "loss": 0.8829,
      "step": 2240
    },
    {
      "epoch": 1.2431778929188255,
      "grad_norm": 1.2887710332870483,
      "learning_rate": 1.2089665653495441e-05,
      "loss": 0.8823,
      "step": 2250
    },
    {
      "epoch": 1.2487046632124352,
      "grad_norm": 1.2584024667739868,
      "learning_rate": 1.2051671732522798e-05,
      "loss": 0.9002,
      "step": 2260
    },
    {
      "epoch": 1.254231433506045,
      "grad_norm": 1.1838129758834839,
      "learning_rate": 1.2013677811550153e-05,
      "loss": 0.8432,
      "step": 2270
    },
    {
      "epoch": 1.2597582037996546,
      "grad_norm": 1.4636061191558838,
      "learning_rate": 1.197568389057751e-05,
      "loss": 0.8963,
      "step": 2280
    },
    {
      "epoch": 1.2652849740932641,
      "grad_norm": 1.3496267795562744,
      "learning_rate": 1.1937689969604865e-05,
      "loss": 0.8516,
      "step": 2290
    },
    {
      "epoch": 1.270811744386874,
      "grad_norm": 1.2719062566757202,
      "learning_rate": 1.1899696048632218e-05,
      "loss": 0.8534,
      "step": 2300
    },
    {
      "epoch": 1.270811744386874,
      "eval_loss": 0.8864766359329224,
      "eval_runtime": 406.7313,
      "eval_samples_per_second": 3.956,
      "eval_steps_per_second": 0.497,
      "step": 2300
    },
    {
      "epoch": 1.2763385146804835,
      "grad_norm": 1.2875280380249023,
      "learning_rate": 1.1861702127659575e-05,
      "loss": 0.8926,
      "step": 2310
    },
    {
      "epoch": 1.2818652849740932,
      "grad_norm": 1.2704026699066162,
      "learning_rate": 1.182370820668693e-05,
      "loss": 0.8884,
      "step": 2320
    },
    {
      "epoch": 1.287392055267703,
      "grad_norm": 1.2416757345199585,
      "learning_rate": 1.1785714285714287e-05,
      "loss": 0.7952,
      "step": 2330
    },
    {
      "epoch": 1.2929188255613127,
      "grad_norm": 1.4571244716644287,
      "learning_rate": 1.174772036474164e-05,
      "loss": 0.8875,
      "step": 2340
    },
    {
      "epoch": 1.2984455958549224,
      "grad_norm": 1.3489186763763428,
      "learning_rate": 1.1709726443768998e-05,
      "loss": 0.8806,
      "step": 2350
    },
    {
      "epoch": 1.3039723661485318,
      "grad_norm": 1.2782340049743652,
      "learning_rate": 1.1671732522796353e-05,
      "loss": 0.8542,
      "step": 2360
    },
    {
      "epoch": 1.3094991364421416,
      "grad_norm": 1.5137919187545776,
      "learning_rate": 1.163373860182371e-05,
      "loss": 0.8926,
      "step": 2370
    },
    {
      "epoch": 1.3150259067357513,
      "grad_norm": 1.3198723793029785,
      "learning_rate": 1.1595744680851065e-05,
      "loss": 0.929,
      "step": 2380
    },
    {
      "epoch": 1.320552677029361,
      "grad_norm": 1.2884780168533325,
      "learning_rate": 1.1557750759878422e-05,
      "loss": 0.8992,
      "step": 2390
    },
    {
      "epoch": 1.3260794473229707,
      "grad_norm": 1.430092692375183,
      "learning_rate": 1.1519756838905775e-05,
      "loss": 0.8704,
      "step": 2400
    },
    {
      "epoch": 1.3260794473229707,
      "eval_loss": 0.8847769498825073,
      "eval_runtime": 407.0733,
      "eval_samples_per_second": 3.953,
      "eval_steps_per_second": 0.496,
      "step": 2400
    },
    {
      "epoch": 1.3316062176165804,
      "grad_norm": 1.3924156427383423,
      "learning_rate": 1.1481762917933132e-05,
      "loss": 0.821,
      "step": 2410
    },
    {
      "epoch": 1.33713298791019,
      "grad_norm": 1.4266258478164673,
      "learning_rate": 1.1443768996960487e-05,
      "loss": 0.8646,
      "step": 2420
    },
    {
      "epoch": 1.3426597582037996,
      "grad_norm": 1.3370020389556885,
      "learning_rate": 1.1405775075987844e-05,
      "loss": 0.8353,
      "step": 2430
    },
    {
      "epoch": 1.3481865284974093,
      "grad_norm": 1.2270827293395996,
      "learning_rate": 1.1367781155015198e-05,
      "loss": 0.8152,
      "step": 2440
    },
    {
      "epoch": 1.353713298791019,
      "grad_norm": 1.068640112876892,
      "learning_rate": 1.1329787234042555e-05,
      "loss": 0.8919,
      "step": 2450
    },
    {
      "epoch": 1.3592400690846287,
      "grad_norm": 1.2488890886306763,
      "learning_rate": 1.129179331306991e-05,
      "loss": 0.8974,
      "step": 2460
    },
    {
      "epoch": 1.3647668393782384,
      "grad_norm": 1.2184057235717773,
      "learning_rate": 1.1253799392097265e-05,
      "loss": 0.8327,
      "step": 2470
    },
    {
      "epoch": 1.3702936096718479,
      "grad_norm": 1.36710524559021,
      "learning_rate": 1.1215805471124622e-05,
      "loss": 0.9061,
      "step": 2480
    },
    {
      "epoch": 1.3758203799654578,
      "grad_norm": 1.3422045707702637,
      "learning_rate": 1.1177811550151975e-05,
      "loss": 0.7896,
      "step": 2490
    },
    {
      "epoch": 1.3813471502590673,
      "grad_norm": 1.1311008930206299,
      "learning_rate": 1.1139817629179332e-05,
      "loss": 0.8752,
      "step": 2500
    },
    {
      "epoch": 1.3813471502590673,
      "eval_loss": 0.8829222321510315,
      "eval_runtime": 409.6013,
      "eval_samples_per_second": 3.928,
      "eval_steps_per_second": 0.493,
      "step": 2500
    },
    {
      "epoch": 1.386873920552677,
      "grad_norm": 1.2309397459030151,
      "learning_rate": 1.1101823708206687e-05,
      "loss": 0.8772,
      "step": 2510
    },
    {
      "epoch": 1.3924006908462867,
      "grad_norm": 1.3612717390060425,
      "learning_rate": 1.1063829787234044e-05,
      "loss": 0.8892,
      "step": 2520
    },
    {
      "epoch": 1.3979274611398964,
      "grad_norm": 1.4035810232162476,
      "learning_rate": 1.10258358662614e-05,
      "loss": 0.8994,
      "step": 2530
    },
    {
      "epoch": 1.4034542314335061,
      "grad_norm": 1.3251692056655884,
      "learning_rate": 1.0987841945288754e-05,
      "loss": 0.893,
      "step": 2540
    },
    {
      "epoch": 1.4089810017271156,
      "grad_norm": 1.327424168586731,
      "learning_rate": 1.094984802431611e-05,
      "loss": 0.8951,
      "step": 2550
    },
    {
      "epoch": 1.4145077720207253,
      "grad_norm": 1.1541088819503784,
      "learning_rate": 1.0911854103343466e-05,
      "loss": 0.8487,
      "step": 2560
    },
    {
      "epoch": 1.420034542314335,
      "grad_norm": 1.360602617263794,
      "learning_rate": 1.0873860182370822e-05,
      "loss": 0.8835,
      "step": 2570
    },
    {
      "epoch": 1.4255613126079447,
      "grad_norm": 1.205650806427002,
      "learning_rate": 1.0835866261398179e-05,
      "loss": 0.8801,
      "step": 2580
    },
    {
      "epoch": 1.4310880829015544,
      "grad_norm": 1.4974271059036255,
      "learning_rate": 1.0797872340425532e-05,
      "loss": 0.8997,
      "step": 2590
    },
    {
      "epoch": 1.4366148531951641,
      "grad_norm": 1.3462077379226685,
      "learning_rate": 1.0759878419452889e-05,
      "loss": 0.8739,
      "step": 2600
    },
    {
      "epoch": 1.4366148531951641,
      "eval_loss": 0.8813614845275879,
      "eval_runtime": 411.1077,
      "eval_samples_per_second": 3.914,
      "eval_steps_per_second": 0.491,
      "step": 2600
    },
    {
      "epoch": 1.4421416234887738,
      "grad_norm": 1.1907457113265991,
      "learning_rate": 1.0721884498480244e-05,
      "loss": 0.8217,
      "step": 2610
    },
    {
      "epoch": 1.4476683937823833,
      "grad_norm": 1.3782551288604736,
      "learning_rate": 1.0683890577507601e-05,
      "loss": 0.9314,
      "step": 2620
    },
    {
      "epoch": 1.453195164075993,
      "grad_norm": 1.8974757194519043,
      "learning_rate": 1.0645896656534956e-05,
      "loss": 0.8334,
      "step": 2630
    },
    {
      "epoch": 1.4587219343696027,
      "grad_norm": 1.3432660102844238,
      "learning_rate": 1.060790273556231e-05,
      "loss": 0.8706,
      "step": 2640
    },
    {
      "epoch": 1.4642487046632124,
      "grad_norm": 1.2117891311645508,
      "learning_rate": 1.0569908814589666e-05,
      "loss": 0.8329,
      "step": 2650
    },
    {
      "epoch": 1.4697754749568221,
      "grad_norm": 1.3545821905136108,
      "learning_rate": 1.0531914893617022e-05,
      "loss": 0.8744,
      "step": 2660
    },
    {
      "epoch": 1.4753022452504319,
      "grad_norm": 1.2686171531677246,
      "learning_rate": 1.0493920972644378e-05,
      "loss": 0.8954,
      "step": 2670
    },
    {
      "epoch": 1.4808290155440416,
      "grad_norm": 1.6842312812805176,
      "learning_rate": 1.0455927051671732e-05,
      "loss": 0.8927,
      "step": 2680
    },
    {
      "epoch": 1.486355785837651,
      "grad_norm": 1.4721858501434326,
      "learning_rate": 1.0417933130699089e-05,
      "loss": 0.974,
      "step": 2690
    },
    {
      "epoch": 1.4918825561312608,
      "grad_norm": 1.2322465181350708,
      "learning_rate": 1.0379939209726444e-05,
      "loss": 0.857,
      "step": 2700
    },
    {
      "epoch": 1.4918825561312608,
      "eval_loss": 0.879459023475647,
      "eval_runtime": 410.6254,
      "eval_samples_per_second": 3.918,
      "eval_steps_per_second": 0.492,
      "step": 2700
    },
    {
      "epoch": 1.4974093264248705,
      "grad_norm": 1.3593071699142456,
      "learning_rate": 1.0341945288753801e-05,
      "loss": 0.7809,
      "step": 2710
    },
    {
      "epoch": 1.5029360967184802,
      "grad_norm": 1.201200008392334,
      "learning_rate": 1.0303951367781156e-05,
      "loss": 0.8721,
      "step": 2720
    },
    {
      "epoch": 1.5084628670120899,
      "grad_norm": 1.4617048501968384,
      "learning_rate": 1.0265957446808513e-05,
      "loss": 0.8536,
      "step": 2730
    },
    {
      "epoch": 1.5139896373056994,
      "grad_norm": 1.498688817024231,
      "learning_rate": 1.0227963525835866e-05,
      "loss": 0.8482,
      "step": 2740
    },
    {
      "epoch": 1.5195164075993093,
      "grad_norm": 1.3123328685760498,
      "learning_rate": 1.0189969604863223e-05,
      "loss": 0.8532,
      "step": 2750
    },
    {
      "epoch": 1.5250431778929188,
      "grad_norm": 1.282550573348999,
      "learning_rate": 1.0151975683890578e-05,
      "loss": 0.8595,
      "step": 2760
    },
    {
      "epoch": 1.5305699481865285,
      "grad_norm": 1.1917682886123657,
      "learning_rate": 1.0113981762917935e-05,
      "loss": 0.8375,
      "step": 2770
    },
    {
      "epoch": 1.5360967184801382,
      "grad_norm": 1.3991687297821045,
      "learning_rate": 1.0075987841945289e-05,
      "loss": 0.8546,
      "step": 2780
    },
    {
      "epoch": 1.5416234887737479,
      "grad_norm": 1.1729762554168701,
      "learning_rate": 1.0037993920972646e-05,
      "loss": 0.8388,
      "step": 2790
    },
    {
      "epoch": 1.5471502590673576,
      "grad_norm": 1.3649524450302124,
      "learning_rate": 1e-05,
      "loss": 0.9554,
      "step": 2800
    },
    {
      "epoch": 1.5471502590673576,
      "eval_loss": 0.8777433633804321,
      "eval_runtime": 412.0899,
      "eval_samples_per_second": 3.904,
      "eval_steps_per_second": 0.49,
      "step": 2800
    },
    {
      "epoch": 1.552677029360967,
      "grad_norm": 1.3869556188583374,
      "learning_rate": 9.962006079027356e-06,
      "loss": 0.85,
      "step": 2810
    },
    {
      "epoch": 1.558203799654577,
      "grad_norm": 1.3381309509277344,
      "learning_rate": 9.924012158054713e-06,
      "loss": 0.8765,
      "step": 2820
    },
    {
      "epoch": 1.5637305699481865,
      "grad_norm": 1.2622616291046143,
      "learning_rate": 9.886018237082068e-06,
      "loss": 0.899,
      "step": 2830
    },
    {
      "epoch": 1.5692573402417962,
      "grad_norm": 1.3081823587417603,
      "learning_rate": 9.848024316109423e-06,
      "loss": 0.8719,
      "step": 2840
    },
    {
      "epoch": 1.574784110535406,
      "grad_norm": 1.364388346672058,
      "learning_rate": 9.81003039513678e-06,
      "loss": 0.8447,
      "step": 2850
    },
    {
      "epoch": 1.5803108808290154,
      "grad_norm": 1.2667834758758545,
      "learning_rate": 9.772036474164135e-06,
      "loss": 0.8756,
      "step": 2860
    },
    {
      "epoch": 1.5858376511226253,
      "grad_norm": 1.2628216743469238,
      "learning_rate": 9.73404255319149e-06,
      "loss": 0.9277,
      "step": 2870
    },
    {
      "epoch": 1.5913644214162348,
      "grad_norm": 1.3763014078140259,
      "learning_rate": 9.696048632218846e-06,
      "loss": 0.824,
      "step": 2880
    },
    {
      "epoch": 1.5968911917098445,
      "grad_norm": 1.2883219718933105,
      "learning_rate": 9.6580547112462e-06,
      "loss": 0.8391,
      "step": 2890
    },
    {
      "epoch": 1.6024179620034542,
      "grad_norm": 1.2573589086532593,
      "learning_rate": 9.620060790273556e-06,
      "loss": 0.8754,
      "step": 2900
    },
    {
      "epoch": 1.6024179620034542,
      "eval_loss": 0.8765857815742493,
      "eval_runtime": 413.4299,
      "eval_samples_per_second": 3.892,
      "eval_steps_per_second": 0.489,
      "step": 2900
    },
    {
      "epoch": 1.607944732297064,
      "grad_norm": 1.2261995077133179,
      "learning_rate": 9.582066869300913e-06,
      "loss": 0.8813,
      "step": 2910
    },
    {
      "epoch": 1.6134715025906736,
      "grad_norm": 1.16396963596344,
      "learning_rate": 9.544072948328268e-06,
      "loss": 0.9068,
      "step": 2920
    },
    {
      "epoch": 1.618998272884283,
      "grad_norm": 1.3910537958145142,
      "learning_rate": 9.506079027355623e-06,
      "loss": 0.8154,
      "step": 2930
    },
    {
      "epoch": 1.624525043177893,
      "grad_norm": 1.3554630279541016,
      "learning_rate": 9.46808510638298e-06,
      "loss": 0.8033,
      "step": 2940
    },
    {
      "epoch": 1.6300518134715025,
      "grad_norm": 1.3107385635375977,
      "learning_rate": 9.430091185410335e-06,
      "loss": 0.8882,
      "step": 2950
    },
    {
      "epoch": 1.6355785837651122,
      "grad_norm": 1.4520992040634155,
      "learning_rate": 9.39209726443769e-06,
      "loss": 0.8261,
      "step": 2960
    },
    {
      "epoch": 1.641105354058722,
      "grad_norm": 1.4260917901992798,
      "learning_rate": 9.354103343465046e-06,
      "loss": 0.8732,
      "step": 2970
    },
    {
      "epoch": 1.6466321243523316,
      "grad_norm": 1.32429039478302,
      "learning_rate": 9.316109422492402e-06,
      "loss": 0.8569,
      "step": 2980
    },
    {
      "epoch": 1.6521588946459413,
      "grad_norm": 1.4284535646438599,
      "learning_rate": 9.278115501519758e-06,
      "loss": 0.8831,
      "step": 2990
    },
    {
      "epoch": 1.6576856649395508,
      "grad_norm": 1.3999006748199463,
      "learning_rate": 9.240121580547113e-06,
      "loss": 0.8645,
      "step": 3000
    },
    {
      "epoch": 1.6576856649395508,
      "eval_loss": 0.8744189143180847,
      "eval_runtime": 412.9611,
      "eval_samples_per_second": 3.896,
      "eval_steps_per_second": 0.489,
      "step": 3000
    },
    {
      "epoch": 1.6632124352331608,
      "grad_norm": 1.5880887508392334,
      "learning_rate": 9.20212765957447e-06,
      "loss": 0.8384,
      "step": 3010
    },
    {
      "epoch": 1.6687392055267702,
      "grad_norm": 1.370045781135559,
      "learning_rate": 9.164133738601825e-06,
      "loss": 0.8647,
      "step": 3020
    },
    {
      "epoch": 1.67426597582038,
      "grad_norm": 1.4025508165359497,
      "learning_rate": 9.12613981762918e-06,
      "loss": 0.9314,
      "step": 3030
    },
    {
      "epoch": 1.6797927461139897,
      "grad_norm": 1.3389053344726562,
      "learning_rate": 9.088145896656537e-06,
      "loss": 0.9046,
      "step": 3040
    },
    {
      "epoch": 1.6853195164075994,
      "grad_norm": 1.449632167816162,
      "learning_rate": 9.050151975683892e-06,
      "loss": 0.9125,
      "step": 3050
    },
    {
      "epoch": 1.690846286701209,
      "grad_norm": 1.318002700805664,
      "learning_rate": 9.012158054711247e-06,
      "loss": 0.8321,
      "step": 3060
    },
    {
      "epoch": 1.6963730569948186,
      "grad_norm": 1.3635163307189941,
      "learning_rate": 8.974164133738602e-06,
      "loss": 0.8587,
      "step": 3070
    },
    {
      "epoch": 1.7018998272884285,
      "grad_norm": 1.4829024076461792,
      "learning_rate": 8.936170212765958e-06,
      "loss": 0.8528,
      "step": 3080
    },
    {
      "epoch": 1.707426597582038,
      "grad_norm": 1.4694727659225464,
      "learning_rate": 8.898176291793313e-06,
      "loss": 0.8148,
      "step": 3090
    },
    {
      "epoch": 1.7129533678756477,
      "grad_norm": 1.3115614652633667,
      "learning_rate": 8.86018237082067e-06,
      "loss": 0.852,
      "step": 3100
    },
    {
      "epoch": 1.7129533678756477,
      "eval_loss": 0.872990608215332,
      "eval_runtime": 414.0147,
      "eval_samples_per_second": 3.886,
      "eval_steps_per_second": 0.488,
      "step": 3100
    },
    {
      "epoch": 1.7184801381692574,
      "grad_norm": 1.3031429052352905,
      "learning_rate": 8.822188449848025e-06,
      "loss": 0.8296,
      "step": 3110
    },
    {
      "epoch": 1.7240069084628669,
      "grad_norm": 1.361525535583496,
      "learning_rate": 8.78419452887538e-06,
      "loss": 0.8157,
      "step": 3120
    },
    {
      "epoch": 1.7295336787564768,
      "grad_norm": 1.262392282485962,
      "learning_rate": 8.746200607902737e-06,
      "loss": 0.8532,
      "step": 3130
    },
    {
      "epoch": 1.7350604490500863,
      "grad_norm": 1.499038577079773,
      "learning_rate": 8.708206686930092e-06,
      "loss": 0.8448,
      "step": 3140
    },
    {
      "epoch": 1.740587219343696,
      "grad_norm": 1.1626183986663818,
      "learning_rate": 8.670212765957447e-06,
      "loss": 0.8533,
      "step": 3150
    },
    {
      "epoch": 1.7461139896373057,
      "grad_norm": 1.3266111612319946,
      "learning_rate": 8.632218844984804e-06,
      "loss": 0.8389,
      "step": 3160
    },
    {
      "epoch": 1.7516407599309154,
      "grad_norm": 1.3293850421905518,
      "learning_rate": 8.59422492401216e-06,
      "loss": 0.8779,
      "step": 3170
    },
    {
      "epoch": 1.757167530224525,
      "grad_norm": 1.6631613969802856,
      "learning_rate": 8.556231003039514e-06,
      "loss": 0.847,
      "step": 3180
    },
    {
      "epoch": 1.7626943005181346,
      "grad_norm": 1.5835695266723633,
      "learning_rate": 8.51823708206687e-06,
      "loss": 0.8064,
      "step": 3190
    },
    {
      "epoch": 1.7682210708117445,
      "grad_norm": 1.3504414558410645,
      "learning_rate": 8.480243161094226e-06,
      "loss": 0.8483,
      "step": 3200
    },
    {
      "epoch": 1.7682210708117445,
      "eval_loss": 0.8715211749076843,
      "eval_runtime": 414.3952,
      "eval_samples_per_second": 3.883,
      "eval_steps_per_second": 0.487,
      "step": 3200
    },
    {
      "epoch": 1.773747841105354,
      "grad_norm": 1.1991164684295654,
      "learning_rate": 8.442249240121582e-06,
      "loss": 0.8238,
      "step": 3210
    },
    {
      "epoch": 1.7792746113989637,
      "grad_norm": 1.495275855064392,
      "learning_rate": 8.404255319148937e-06,
      "loss": 0.8452,
      "step": 3220
    },
    {
      "epoch": 1.7848013816925734,
      "grad_norm": 1.3595046997070312,
      "learning_rate": 8.366261398176294e-06,
      "loss": 0.9024,
      "step": 3230
    },
    {
      "epoch": 1.7903281519861831,
      "grad_norm": 1.4959017038345337,
      "learning_rate": 8.328267477203647e-06,
      "loss": 0.8423,
      "step": 3240
    },
    {
      "epoch": 1.7958549222797928,
      "grad_norm": 1.4266194105148315,
      "learning_rate": 8.290273556231004e-06,
      "loss": 0.875,
      "step": 3250
    },
    {
      "epoch": 1.8013816925734023,
      "grad_norm": 1.5036544799804688,
      "learning_rate": 8.252279635258359e-06,
      "loss": 0.8512,
      "step": 3260
    },
    {
      "epoch": 1.8069084628670122,
      "grad_norm": 1.3831334114074707,
      "learning_rate": 8.214285714285714e-06,
      "loss": 0.8507,
      "step": 3270
    },
    {
      "epoch": 1.8124352331606217,
      "grad_norm": 1.5799064636230469,
      "learning_rate": 8.176291793313071e-06,
      "loss": 0.8777,
      "step": 3280
    },
    {
      "epoch": 1.8179620034542314,
      "grad_norm": 1.3975163698196411,
      "learning_rate": 8.138297872340426e-06,
      "loss": 0.8443,
      "step": 3290
    },
    {
      "epoch": 1.8234887737478411,
      "grad_norm": 1.3383190631866455,
      "learning_rate": 8.100303951367782e-06,
      "loss": 0.8298,
      "step": 3300
    },
    {
      "epoch": 1.8234887737478411,
      "eval_loss": 0.869315505027771,
      "eval_runtime": 412.5752,
      "eval_samples_per_second": 3.9,
      "eval_steps_per_second": 0.49,
      "step": 3300
    },
    {
      "epoch": 1.8290155440414506,
      "grad_norm": 1.4342100620269775,
      "learning_rate": 8.062310030395137e-06,
      "loss": 0.8978,
      "step": 3310
    },
    {
      "epoch": 1.8345423143350605,
      "grad_norm": 1.4034696817398071,
      "learning_rate": 8.024316109422494e-06,
      "loss": 0.8698,
      "step": 3320
    },
    {
      "epoch": 1.84006908462867,
      "grad_norm": 1.3554139137268066,
      "learning_rate": 7.986322188449849e-06,
      "loss": 0.8871,
      "step": 3330
    },
    {
      "epoch": 1.84559585492228,
      "grad_norm": 1.5627427101135254,
      "learning_rate": 7.948328267477204e-06,
      "loss": 0.8029,
      "step": 3340
    },
    {
      "epoch": 1.8511226252158894,
      "grad_norm": 1.335302472114563,
      "learning_rate": 7.91033434650456e-06,
      "loss": 0.8372,
      "step": 3350
    },
    {
      "epoch": 1.8566493955094991,
      "grad_norm": 1.4160910844802856,
      "learning_rate": 7.872340425531916e-06,
      "loss": 0.8731,
      "step": 3360
    },
    {
      "epoch": 1.8621761658031089,
      "grad_norm": 1.3941198587417603,
      "learning_rate": 7.834346504559271e-06,
      "loss": 0.8764,
      "step": 3370
    },
    {
      "epoch": 1.8677029360967183,
      "grad_norm": 1.4005900621414185,
      "learning_rate": 7.796352583586628e-06,
      "loss": 0.8228,
      "step": 3380
    },
    {
      "epoch": 1.8732297063903283,
      "grad_norm": 1.1897531747817993,
      "learning_rate": 7.758358662613983e-06,
      "loss": 0.8669,
      "step": 3390
    },
    {
      "epoch": 1.8787564766839377,
      "grad_norm": 1.46744704246521,
      "learning_rate": 7.720364741641338e-06,
      "loss": 0.8491,
      "step": 3400
    },
    {
      "epoch": 1.8787564766839377,
      "eval_loss": 0.8659903407096863,
      "eval_runtime": 411.7465,
      "eval_samples_per_second": 3.908,
      "eval_steps_per_second": 0.491,
      "step": 3400
    },
    {
      "epoch": 1.8842832469775475,
      "grad_norm": 1.5178241729736328,
      "learning_rate": 7.682370820668693e-06,
      "loss": 0.9123,
      "step": 3410
    },
    {
      "epoch": 1.8898100172711572,
      "grad_norm": 1.3122875690460205,
      "learning_rate": 7.644376899696049e-06,
      "loss": 0.8413,
      "step": 3420
    },
    {
      "epoch": 1.8953367875647669,
      "grad_norm": 1.4577590227127075,
      "learning_rate": 7.606382978723405e-06,
      "loss": 0.8575,
      "step": 3430
    },
    {
      "epoch": 1.9008635578583766,
      "grad_norm": 1.4779012203216553,
      "learning_rate": 7.56838905775076e-06,
      "loss": 0.8721,
      "step": 3440
    },
    {
      "epoch": 1.906390328151986,
      "grad_norm": 1.5092037916183472,
      "learning_rate": 7.530395136778116e-06,
      "loss": 0.8396,
      "step": 3450
    },
    {
      "epoch": 1.911917098445596,
      "grad_norm": 1.6155380010604858,
      "learning_rate": 7.492401215805472e-06,
      "loss": 0.8249,
      "step": 3460
    },
    {
      "epoch": 1.9174438687392055,
      "grad_norm": 1.5102035999298096,
      "learning_rate": 7.454407294832827e-06,
      "loss": 0.7883,
      "step": 3470
    },
    {
      "epoch": 1.9229706390328152,
      "grad_norm": 1.3685204982757568,
      "learning_rate": 7.416413373860183e-06,
      "loss": 0.8343,
      "step": 3480
    },
    {
      "epoch": 1.9284974093264249,
      "grad_norm": 1.3156789541244507,
      "learning_rate": 7.378419452887538e-06,
      "loss": 0.8484,
      "step": 3490
    },
    {
      "epoch": 1.9340241796200346,
      "grad_norm": 1.2990835905075073,
      "learning_rate": 7.340425531914894e-06,
      "loss": 0.9164,
      "step": 3500
    },
    {
      "epoch": 1.9340241796200346,
      "eval_loss": 0.8613579273223877,
      "eval_runtime": 409.223,
      "eval_samples_per_second": 3.932,
      "eval_steps_per_second": 0.494,
      "step": 3500
    },
    {
      "epoch": 1.9395509499136443,
      "grad_norm": 1.2220433950424194,
      "learning_rate": 7.30243161094225e-06,
      "loss": 0.8273,
      "step": 3510
    },
    {
      "epoch": 1.9450777202072538,
      "grad_norm": 1.3529489040374756,
      "learning_rate": 7.2644376899696055e-06,
      "loss": 0.8316,
      "step": 3520
    },
    {
      "epoch": 1.9506044905008637,
      "grad_norm": 1.2564594745635986,
      "learning_rate": 7.2264437689969615e-06,
      "loss": 0.848,
      "step": 3530
    },
    {
      "epoch": 1.9561312607944732,
      "grad_norm": 1.3982447385787964,
      "learning_rate": 7.188449848024317e-06,
      "loss": 0.8603,
      "step": 3540
    },
    {
      "epoch": 1.961658031088083,
      "grad_norm": 1.3163793087005615,
      "learning_rate": 7.150455927051673e-06,
      "loss": 0.8253,
      "step": 3550
    },
    {
      "epoch": 1.9671848013816926,
      "grad_norm": 1.474051833152771,
      "learning_rate": 7.112462006079029e-06,
      "loss": 0.8926,
      "step": 3560
    },
    {
      "epoch": 1.972711571675302,
      "grad_norm": 1.3133007287979126,
      "learning_rate": 7.074468085106384e-06,
      "loss": 0.82,
      "step": 3570
    },
    {
      "epoch": 1.978238341968912,
      "grad_norm": 1.3367422819137573,
      "learning_rate": 7.036474164133738e-06,
      "loss": 0.844,
      "step": 3580
    },
    {
      "epoch": 1.9837651122625215,
      "grad_norm": 1.4713895320892334,
      "learning_rate": 6.998480243161094e-06,
      "loss": 0.8089,
      "step": 3590
    },
    {
      "epoch": 1.9892918825561312,
      "grad_norm": 1.4699456691741943,
      "learning_rate": 6.96048632218845e-06,
      "loss": 0.8955,
      "step": 3600
    },
    {
      "epoch": 1.9892918825561312,
      "eval_loss": 0.8580969572067261,
      "eval_runtime": 412.1261,
      "eval_samples_per_second": 3.904,
      "eval_steps_per_second": 0.49,
      "step": 3600
    },
    {
      "epoch": 1.994818652849741,
      "grad_norm": 1.3270128965377808,
      "learning_rate": 6.9224924012158054e-06,
      "loss": 0.8244,
      "step": 3610
    },
    {
      "epoch": 2.0,
      "grad_norm": 3.0144429206848145,
      "learning_rate": 6.8844984802431615e-06,
      "loss": 0.844,
      "step": 3620
    },
    {
      "epoch": 2.0055267702936095,
      "grad_norm": 1.5101441144943237,
      "learning_rate": 6.846504559270517e-06,
      "loss": 0.8465,
      "step": 3630
    },
    {
      "epoch": 2.0110535405872194,
      "grad_norm": 1.36057710647583,
      "learning_rate": 6.808510638297873e-06,
      "loss": 0.7737,
      "step": 3640
    },
    {
      "epoch": 2.016580310880829,
      "grad_norm": 1.5170961618423462,
      "learning_rate": 6.770516717325229e-06,
      "loss": 0.8368,
      "step": 3650
    },
    {
      "epoch": 2.022107081174439,
      "grad_norm": 1.4899380207061768,
      "learning_rate": 6.732522796352584e-06,
      "loss": 0.832,
      "step": 3660
    },
    {
      "epoch": 2.0276338514680483,
      "grad_norm": 1.4696952104568481,
      "learning_rate": 6.69452887537994e-06,
      "loss": 0.8522,
      "step": 3670
    },
    {
      "epoch": 2.0331606217616582,
      "grad_norm": 1.428343653678894,
      "learning_rate": 6.656534954407296e-06,
      "loss": 0.8345,
      "step": 3680
    },
    {
      "epoch": 2.0386873920552677,
      "grad_norm": 1.3861101865768433,
      "learning_rate": 6.618541033434651e-06,
      "loss": 0.8833,
      "step": 3690
    },
    {
      "epoch": 2.044214162348877,
      "grad_norm": 1.5904704332351685,
      "learning_rate": 6.580547112462007e-06,
      "loss": 0.7832,
      "step": 3700
    },
    {
      "epoch": 2.044214162348877,
      "eval_loss": 0.8571814298629761,
      "eval_runtime": 412.4637,
      "eval_samples_per_second": 3.901,
      "eval_steps_per_second": 0.49,
      "step": 3700
    },
    {
      "epoch": 2.049740932642487,
      "grad_norm": 1.1397805213928223,
      "learning_rate": 6.542553191489362e-06,
      "loss": 0.8549,
      "step": 3710
    },
    {
      "epoch": 2.0552677029360966,
      "grad_norm": 1.365065574645996,
      "learning_rate": 6.504559270516718e-06,
      "loss": 0.8696,
      "step": 3720
    },
    {
      "epoch": 2.0607944732297065,
      "grad_norm": 1.4921369552612305,
      "learning_rate": 6.466565349544074e-06,
      "loss": 0.8463,
      "step": 3730
    },
    {
      "epoch": 2.066321243523316,
      "grad_norm": 1.3377470970153809,
      "learning_rate": 6.4285714285714295e-06,
      "loss": 0.8459,
      "step": 3740
    },
    {
      "epoch": 2.0718480138169255,
      "grad_norm": 1.4421480894088745,
      "learning_rate": 6.3905775075987855e-06,
      "loss": 0.8203,
      "step": 3750
    },
    {
      "epoch": 2.0773747841105354,
      "grad_norm": 1.404541254043579,
      "learning_rate": 6.35258358662614e-06,
      "loss": 0.7952,
      "step": 3760
    },
    {
      "epoch": 2.082901554404145,
      "grad_norm": 1.6754350662231445,
      "learning_rate": 6.314589665653496e-06,
      "loss": 0.8526,
      "step": 3770
    },
    {
      "epoch": 2.088428324697755,
      "grad_norm": 1.4852930307388306,
      "learning_rate": 6.276595744680851e-06,
      "loss": 0.8509,
      "step": 3780
    },
    {
      "epoch": 2.0939550949913643,
      "grad_norm": 1.3489636182785034,
      "learning_rate": 6.238601823708207e-06,
      "loss": 0.7923,
      "step": 3790
    },
    {
      "epoch": 2.0994818652849743,
      "grad_norm": 1.2679436206817627,
      "learning_rate": 6.200607902735562e-06,
      "loss": 0.8023,
      "step": 3800
    },
    {
      "epoch": 2.0994818652849743,
      "eval_loss": 0.8565300703048706,
      "eval_runtime": 413.5974,
      "eval_samples_per_second": 3.89,
      "eval_steps_per_second": 0.488,
      "step": 3800
    },
    {
      "epoch": 2.1050086355785838,
      "grad_norm": 1.3061535358428955,
      "learning_rate": 6.162613981762918e-06,
      "loss": 0.8457,
      "step": 3810
    },
    {
      "epoch": 2.1105354058721932,
      "grad_norm": 1.3328120708465576,
      "learning_rate": 6.124620060790274e-06,
      "loss": 0.804,
      "step": 3820
    },
    {
      "epoch": 2.116062176165803,
      "grad_norm": 1.4606022834777832,
      "learning_rate": 6.086626139817629e-06,
      "loss": 0.8652,
      "step": 3830
    },
    {
      "epoch": 2.1215889464594127,
      "grad_norm": 1.3119585514068604,
      "learning_rate": 6.0486322188449854e-06,
      "loss": 0.8876,
      "step": 3840
    },
    {
      "epoch": 2.1271157167530226,
      "grad_norm": 1.4768776893615723,
      "learning_rate": 6.010638297872341e-06,
      "loss": 0.8375,
      "step": 3850
    },
    {
      "epoch": 2.132642487046632,
      "grad_norm": 1.3926379680633545,
      "learning_rate": 5.972644376899697e-06,
      "loss": 0.8419,
      "step": 3860
    },
    {
      "epoch": 2.138169257340242,
      "grad_norm": 1.4067656993865967,
      "learning_rate": 5.934650455927053e-06,
      "loss": 0.8621,
      "step": 3870
    },
    {
      "epoch": 2.1436960276338515,
      "grad_norm": 1.4672490358352661,
      "learning_rate": 5.896656534954408e-06,
      "loss": 0.8157,
      "step": 3880
    },
    {
      "epoch": 2.149222797927461,
      "grad_norm": 1.5141842365264893,
      "learning_rate": 5.858662613981764e-06,
      "loss": 0.8362,
      "step": 3890
    },
    {
      "epoch": 2.154749568221071,
      "grad_norm": 1.357302188873291,
      "learning_rate": 5.820668693009119e-06,
      "loss": 0.8632,
      "step": 3900
    },
    {
      "epoch": 2.154749568221071,
      "eval_loss": 0.8556855320930481,
      "eval_runtime": 411.1435,
      "eval_samples_per_second": 3.913,
      "eval_steps_per_second": 0.491,
      "step": 3900
    },
    {
      "epoch": 2.1602763385146804,
      "grad_norm": 1.3758301734924316,
      "learning_rate": 5.782674772036475e-06,
      "loss": 0.84,
      "step": 3910
    },
    {
      "epoch": 2.1658031088082903,
      "grad_norm": 1.5482515096664429,
      "learning_rate": 5.744680851063831e-06,
      "loss": 0.8263,
      "step": 3920
    },
    {
      "epoch": 2.1713298791019,
      "grad_norm": 1.3514280319213867,
      "learning_rate": 5.706686930091185e-06,
      "loss": 0.7725,
      "step": 3930
    },
    {
      "epoch": 2.1768566493955097,
      "grad_norm": 1.4671471118927002,
      "learning_rate": 5.668693009118541e-06,
      "loss": 0.8482,
      "step": 3940
    },
    {
      "epoch": 2.182383419689119,
      "grad_norm": 1.406926155090332,
      "learning_rate": 5.6306990881458966e-06,
      "loss": 0.8091,
      "step": 3950
    },
    {
      "epoch": 2.1879101899827287,
      "grad_norm": 1.649294137954712,
      "learning_rate": 5.592705167173253e-06,
      "loss": 0.8424,
      "step": 3960
    },
    {
      "epoch": 2.1934369602763386,
      "grad_norm": 1.4670833349227905,
      "learning_rate": 5.554711246200608e-06,
      "loss": 0.8735,
      "step": 3970
    },
    {
      "epoch": 2.198963730569948,
      "grad_norm": 1.46408212184906,
      "learning_rate": 5.516717325227964e-06,
      "loss": 0.8825,
      "step": 3980
    },
    {
      "epoch": 2.204490500863558,
      "grad_norm": 1.5362719297409058,
      "learning_rate": 5.47872340425532e-06,
      "loss": 0.8801,
      "step": 3990
    },
    {
      "epoch": 2.2100172711571675,
      "grad_norm": 1.5345417261123657,
      "learning_rate": 5.440729483282675e-06,
      "loss": 0.8856,
      "step": 4000
    },
    {
      "epoch": 2.2100172711571675,
      "eval_loss": 0.8549320697784424,
      "eval_runtime": 400.725,
      "eval_samples_per_second": 4.015,
      "eval_steps_per_second": 0.504,
      "step": 4000
    },
    {
      "epoch": 2.2155440414507774,
      "grad_norm": 1.4564963579177856,
      "learning_rate": 5.402735562310031e-06,
      "loss": 0.8114,
      "step": 4010
    },
    {
      "epoch": 2.221070811744387,
      "grad_norm": 1.4438421726226807,
      "learning_rate": 5.364741641337386e-06,
      "loss": 0.8727,
      "step": 4020
    },
    {
      "epoch": 2.2265975820379964,
      "grad_norm": 1.4190375804901123,
      "learning_rate": 5.326747720364742e-06,
      "loss": 0.7629,
      "step": 4030
    },
    {
      "epoch": 2.2321243523316063,
      "grad_norm": 1.7745081186294556,
      "learning_rate": 5.288753799392098e-06,
      "loss": 0.859,
      "step": 4040
    },
    {
      "epoch": 2.237651122625216,
      "grad_norm": 1.4770976305007935,
      "learning_rate": 5.250759878419453e-06,
      "loss": 0.863,
      "step": 4050
    },
    {
      "epoch": 2.2431778929188257,
      "grad_norm": 1.6940202713012695,
      "learning_rate": 5.212765957446809e-06,
      "loss": 0.8323,
      "step": 4060
    },
    {
      "epoch": 2.2487046632124352,
      "grad_norm": 1.4617091417312622,
      "learning_rate": 5.174772036474165e-06,
      "loss": 0.8232,
      "step": 4070
    },
    {
      "epoch": 2.2542314335060447,
      "grad_norm": 1.3269635438919067,
      "learning_rate": 5.136778115501521e-06,
      "loss": 0.8187,
      "step": 4080
    },
    {
      "epoch": 2.2597582037996546,
      "grad_norm": 1.551003098487854,
      "learning_rate": 5.098784194528877e-06,
      "loss": 0.8855,
      "step": 4090
    },
    {
      "epoch": 2.265284974093264,
      "grad_norm": 1.4218761920928955,
      "learning_rate": 5.060790273556231e-06,
      "loss": 0.8364,
      "step": 4100
    },
    {
      "epoch": 2.265284974093264,
      "eval_loss": 0.8545277714729309,
      "eval_runtime": 390.3109,
      "eval_samples_per_second": 4.122,
      "eval_steps_per_second": 0.518,
      "step": 4100
    },
    {
      "epoch": 2.270811744386874,
      "grad_norm": 1.545441746711731,
      "learning_rate": 5.022796352583587e-06,
      "loss": 0.8317,
      "step": 4110
    },
    {
      "epoch": 2.2763385146804835,
      "grad_norm": 1.5850998163223267,
      "learning_rate": 4.984802431610943e-06,
      "loss": 0.8281,
      "step": 4120
    },
    {
      "epoch": 2.281865284974093,
      "grad_norm": 1.44888174533844,
      "learning_rate": 4.946808510638298e-06,
      "loss": 0.8151,
      "step": 4130
    },
    {
      "epoch": 2.287392055267703,
      "grad_norm": 1.245656132698059,
      "learning_rate": 4.908814589665654e-06,
      "loss": 0.8385,
      "step": 4140
    },
    {
      "epoch": 2.2929188255613124,
      "grad_norm": 1.5643759965896606,
      "learning_rate": 4.870820668693009e-06,
      "loss": 0.8509,
      "step": 4150
    },
    {
      "epoch": 2.2984455958549224,
      "grad_norm": 1.5501216650009155,
      "learning_rate": 4.832826747720365e-06,
      "loss": 0.8282,
      "step": 4160
    },
    {
      "epoch": 2.303972366148532,
      "grad_norm": 1.4959251880645752,
      "learning_rate": 4.7948328267477205e-06,
      "loss": 0.7814,
      "step": 4170
    },
    {
      "epoch": 2.3094991364421418,
      "grad_norm": 1.5796773433685303,
      "learning_rate": 4.7568389057750766e-06,
      "loss": 0.8109,
      "step": 4180
    },
    {
      "epoch": 2.3150259067357513,
      "grad_norm": 1.4500763416290283,
      "learning_rate": 4.718844984802432e-06,
      "loss": 0.8114,
      "step": 4190
    },
    {
      "epoch": 2.3205526770293607,
      "grad_norm": 1.4362657070159912,
      "learning_rate": 4.680851063829788e-06,
      "loss": 0.8502,
      "step": 4200
    },
    {
      "epoch": 2.3205526770293607,
      "eval_loss": 0.854035496711731,
      "eval_runtime": 385.9629,
      "eval_samples_per_second": 4.169,
      "eval_steps_per_second": 0.523,
      "step": 4200
    },
    {
      "epoch": 2.3260794473229707,
      "grad_norm": 1.3114713430404663,
      "learning_rate": 4.642857142857144e-06,
      "loss": 0.8414,
      "step": 4210
    },
    {
      "epoch": 2.33160621761658,
      "grad_norm": 1.5262900590896606,
      "learning_rate": 4.604863221884499e-06,
      "loss": 0.8484,
      "step": 4220
    },
    {
      "epoch": 2.33713298791019,
      "grad_norm": 1.4225975275039673,
      "learning_rate": 4.566869300911854e-06,
      "loss": 0.87,
      "step": 4230
    },
    {
      "epoch": 2.3426597582037996,
      "grad_norm": 1.6196632385253906,
      "learning_rate": 4.52887537993921e-06,
      "loss": 0.799,
      "step": 4240
    },
    {
      "epoch": 2.3481865284974095,
      "grad_norm": 1.3961580991744995,
      "learning_rate": 4.490881458966565e-06,
      "loss": 0.8096,
      "step": 4250
    },
    {
      "epoch": 2.353713298791019,
      "grad_norm": 1.6250110864639282,
      "learning_rate": 4.452887537993921e-06,
      "loss": 0.8529,
      "step": 4260
    },
    {
      "epoch": 2.3592400690846285,
      "grad_norm": 1.3051838874816895,
      "learning_rate": 4.414893617021277e-06,
      "loss": 0.8444,
      "step": 4270
    },
    {
      "epoch": 2.3647668393782384,
      "grad_norm": 1.4260679483413696,
      "learning_rate": 4.3768996960486325e-06,
      "loss": 0.858,
      "step": 4280
    },
    {
      "epoch": 2.370293609671848,
      "grad_norm": 1.508253574371338,
      "learning_rate": 4.3389057750759886e-06,
      "loss": 0.8065,
      "step": 4290
    },
    {
      "epoch": 2.375820379965458,
      "grad_norm": 1.3851253986358643,
      "learning_rate": 4.300911854103344e-06,
      "loss": 0.8784,
      "step": 4300
    },
    {
      "epoch": 2.375820379965458,
      "eval_loss": 0.8535451292991638,
      "eval_runtime": 384.9254,
      "eval_samples_per_second": 4.18,
      "eval_steps_per_second": 0.525,
      "step": 4300
    },
    {
      "epoch": 2.3813471502590673,
      "grad_norm": 1.3579620122909546,
      "learning_rate": 4.2629179331307e-06,
      "loss": 0.8487,
      "step": 4310
    },
    {
      "epoch": 2.386873920552677,
      "grad_norm": 1.5630451440811157,
      "learning_rate": 4.224924012158055e-06,
      "loss": 0.8825,
      "step": 4320
    },
    {
      "epoch": 2.3924006908462867,
      "grad_norm": 1.3390196561813354,
      "learning_rate": 4.18693009118541e-06,
      "loss": 0.8052,
      "step": 4330
    },
    {
      "epoch": 2.397927461139896,
      "grad_norm": 1.5159788131713867,
      "learning_rate": 4.148936170212766e-06,
      "loss": 0.8559,
      "step": 4340
    },
    {
      "epoch": 2.403454231433506,
      "grad_norm": 1.4630053043365479,
      "learning_rate": 4.110942249240122e-06,
      "loss": 0.8061,
      "step": 4350
    },
    {
      "epoch": 2.4089810017271156,
      "grad_norm": 1.3219321966171265,
      "learning_rate": 4.072948328267477e-06,
      "loss": 0.8462,
      "step": 4360
    },
    {
      "epoch": 2.4145077720207255,
      "grad_norm": 1.8430447578430176,
      "learning_rate": 4.034954407294833e-06,
      "loss": 0.8301,
      "step": 4370
    },
    {
      "epoch": 2.420034542314335,
      "grad_norm": 1.4965832233428955,
      "learning_rate": 3.9969604863221885e-06,
      "loss": 0.8535,
      "step": 4380
    },
    {
      "epoch": 2.425561312607945,
      "grad_norm": 1.451429843902588,
      "learning_rate": 3.9589665653495445e-06,
      "loss": 0.8191,
      "step": 4390
    },
    {
      "epoch": 2.4310880829015544,
      "grad_norm": 1.534886360168457,
      "learning_rate": 3.9209726443769005e-06,
      "loss": 0.8841,
      "step": 4400
    },
    {
      "epoch": 2.4310880829015544,
      "eval_loss": 0.8531116843223572,
      "eval_runtime": 387.2747,
      "eval_samples_per_second": 4.155,
      "eval_steps_per_second": 0.522,
      "step": 4400
    },
    {
      "epoch": 2.436614853195164,
      "grad_norm": 1.4842127561569214,
      "learning_rate": 3.882978723404256e-06,
      "loss": 0.8417,
      "step": 4410
    },
    {
      "epoch": 2.442141623488774,
      "grad_norm": 1.5203970670700073,
      "learning_rate": 3.844984802431611e-06,
      "loss": 0.8527,
      "step": 4420
    },
    {
      "epoch": 2.4476683937823833,
      "grad_norm": 1.5310741662979126,
      "learning_rate": 3.806990881458967e-06,
      "loss": 0.863,
      "step": 4430
    },
    {
      "epoch": 2.4531951640759933,
      "grad_norm": 1.5516427755355835,
      "learning_rate": 3.7689969604863225e-06,
      "loss": 0.8729,
      "step": 4440
    },
    {
      "epoch": 2.4587219343696027,
      "grad_norm": 1.3916338682174683,
      "learning_rate": 3.731003039513678e-06,
      "loss": 0.8582,
      "step": 4450
    },
    {
      "epoch": 2.4642487046632127,
      "grad_norm": 1.3889219760894775,
      "learning_rate": 3.6930091185410337e-06,
      "loss": 0.8837,
      "step": 4460
    },
    {
      "epoch": 2.469775474956822,
      "grad_norm": 1.411778450012207,
      "learning_rate": 3.6550151975683897e-06,
      "loss": 0.8106,
      "step": 4470
    },
    {
      "epoch": 2.4753022452504316,
      "grad_norm": 1.4356632232666016,
      "learning_rate": 3.6170212765957453e-06,
      "loss": 0.8021,
      "step": 4480
    },
    {
      "epoch": 2.4808290155440416,
      "grad_norm": 1.4166654348373413,
      "learning_rate": 3.5790273556231005e-06,
      "loss": 0.8003,
      "step": 4490
    },
    {
      "epoch": 2.486355785837651,
      "grad_norm": 1.4683582782745361,
      "learning_rate": 3.541033434650456e-06,
      "loss": 0.8243,
      "step": 4500
    },
    {
      "epoch": 2.486355785837651,
      "eval_loss": 0.8525388836860657,
      "eval_runtime": 389.7474,
      "eval_samples_per_second": 4.128,
      "eval_steps_per_second": 0.518,
      "step": 4500
    },
    {
      "epoch": 2.491882556131261,
      "grad_norm": 1.315543532371521,
      "learning_rate": 3.5030395136778117e-06,
      "loss": 0.8288,
      "step": 4510
    },
    {
      "epoch": 2.4974093264248705,
      "grad_norm": 1.4124482870101929,
      "learning_rate": 3.4650455927051673e-06,
      "loss": 0.8948,
      "step": 4520
    },
    {
      "epoch": 2.5029360967184804,
      "grad_norm": 1.2690386772155762,
      "learning_rate": 3.427051671732523e-06,
      "loss": 0.8551,
      "step": 4530
    },
    {
      "epoch": 2.50846286701209,
      "grad_norm": 1.4607782363891602,
      "learning_rate": 3.389057750759879e-06,
      "loss": 0.7991,
      "step": 4540
    },
    {
      "epoch": 2.5139896373056994,
      "grad_norm": 1.3261631727218628,
      "learning_rate": 3.3510638297872345e-06,
      "loss": 0.8174,
      "step": 4550
    },
    {
      "epoch": 2.5195164075993093,
      "grad_norm": 1.3540955781936646,
      "learning_rate": 3.31306990881459e-06,
      "loss": 0.8287,
      "step": 4560
    },
    {
      "epoch": 2.5250431778929188,
      "grad_norm": 1.254998803138733,
      "learning_rate": 3.2750759878419457e-06,
      "loss": 0.8549,
      "step": 4570
    },
    {
      "epoch": 2.5305699481865283,
      "grad_norm": 2.1593244075775146,
      "learning_rate": 3.237082066869301e-06,
      "loss": 0.858,
      "step": 4580
    },
    {
      "epoch": 2.536096718480138,
      "grad_norm": 1.4146205186843872,
      "learning_rate": 3.1990881458966565e-06,
      "loss": 0.8259,
      "step": 4590
    },
    {
      "epoch": 2.541623488773748,
      "grad_norm": 1.5097651481628418,
      "learning_rate": 3.1610942249240125e-06,
      "loss": 0.8699,
      "step": 4600
    },
    {
      "epoch": 2.541623488773748,
      "eval_loss": 0.852144718170166,
      "eval_runtime": 389.6943,
      "eval_samples_per_second": 4.129,
      "eval_steps_per_second": 0.518,
      "step": 4600
    },
    {
      "epoch": 2.5471502590673576,
      "grad_norm": 1.335886001586914,
      "learning_rate": 3.123100303951368e-06,
      "loss": 0.8341,
      "step": 4610
    },
    {
      "epoch": 2.552677029360967,
      "grad_norm": 1.6003079414367676,
      "learning_rate": 3.0851063829787237e-06,
      "loss": 0.8591,
      "step": 4620
    },
    {
      "epoch": 2.558203799654577,
      "grad_norm": 1.4581390619277954,
      "learning_rate": 3.0471124620060793e-06,
      "loss": 0.8816,
      "step": 4630
    },
    {
      "epoch": 2.5637305699481865,
      "grad_norm": 1.549343466758728,
      "learning_rate": 3.009118541033435e-06,
      "loss": 0.8711,
      "step": 4640
    },
    {
      "epoch": 2.569257340241796,
      "grad_norm": 1.4412426948547363,
      "learning_rate": 2.971124620060791e-06,
      "loss": 0.8143,
      "step": 4650
    },
    {
      "epoch": 2.574784110535406,
      "grad_norm": 1.4863008260726929,
      "learning_rate": 2.9331306990881465e-06,
      "loss": 0.8397,
      "step": 4660
    },
    {
      "epoch": 2.5803108808290154,
      "grad_norm": 1.7630176544189453,
      "learning_rate": 2.8951367781155017e-06,
      "loss": 0.8141,
      "step": 4670
    },
    {
      "epoch": 2.5858376511226253,
      "grad_norm": 1.5520234107971191,
      "learning_rate": 2.8571428571428573e-06,
      "loss": 0.8341,
      "step": 4680
    },
    {
      "epoch": 2.591364421416235,
      "grad_norm": 1.425765872001648,
      "learning_rate": 2.819148936170213e-06,
      "loss": 0.8122,
      "step": 4690
    },
    {
      "epoch": 2.5968911917098447,
      "grad_norm": 1.4517600536346436,
      "learning_rate": 2.7811550151975684e-06,
      "loss": 0.8284,
      "step": 4700
    },
    {
      "epoch": 2.5968911917098447,
      "eval_loss": 0.8516367077827454,
      "eval_runtime": 388.5095,
      "eval_samples_per_second": 4.141,
      "eval_steps_per_second": 0.52,
      "step": 4700
    },
    {
      "epoch": 2.602417962003454,
      "grad_norm": 1.359722375869751,
      "learning_rate": 2.7431610942249245e-06,
      "loss": 0.8046,
      "step": 4710
    },
    {
      "epoch": 2.6079447322970637,
      "grad_norm": 1.6389439105987549,
      "learning_rate": 2.70516717325228e-06,
      "loss": 0.8302,
      "step": 4720
    },
    {
      "epoch": 2.6134715025906736,
      "grad_norm": 1.5207072496414185,
      "learning_rate": 2.6671732522796357e-06,
      "loss": 0.8286,
      "step": 4730
    },
    {
      "epoch": 2.618998272884283,
      "grad_norm": 1.2963316440582275,
      "learning_rate": 2.6291793313069913e-06,
      "loss": 0.8222,
      "step": 4740
    },
    {
      "epoch": 2.624525043177893,
      "grad_norm": 1.5218055248260498,
      "learning_rate": 2.5911854103343464e-06,
      "loss": 0.8494,
      "step": 4750
    },
    {
      "epoch": 2.6300518134715025,
      "grad_norm": 1.4830920696258545,
      "learning_rate": 2.553191489361702e-06,
      "loss": 0.7795,
      "step": 4760
    },
    {
      "epoch": 2.6355785837651124,
      "grad_norm": 1.4652812480926514,
      "learning_rate": 2.5151975683890576e-06,
      "loss": 0.8315,
      "step": 4770
    },
    {
      "epoch": 2.641105354058722,
      "grad_norm": 1.4822955131530762,
      "learning_rate": 2.4772036474164136e-06,
      "loss": 0.8258,
      "step": 4780
    },
    {
      "epoch": 2.6466321243523314,
      "grad_norm": 1.4761905670166016,
      "learning_rate": 2.4392097264437692e-06,
      "loss": 0.8558,
      "step": 4790
    },
    {
      "epoch": 2.6521588946459413,
      "grad_norm": 1.4778610467910767,
      "learning_rate": 2.401215805471125e-06,
      "loss": 0.7915,
      "step": 4800
    },
    {
      "epoch": 2.6521588946459413,
      "eval_loss": 0.851858377456665,
      "eval_runtime": 387.5052,
      "eval_samples_per_second": 4.152,
      "eval_steps_per_second": 0.521,
      "step": 4800
    },
    {
      "epoch": 2.657685664939551,
      "grad_norm": 1.4162497520446777,
      "learning_rate": 2.3632218844984804e-06,
      "loss": 0.8952,
      "step": 4810
    },
    {
      "epoch": 2.6632124352331608,
      "grad_norm": 1.4697898626327515,
      "learning_rate": 2.325227963525836e-06,
      "loss": 0.8826,
      "step": 4820
    },
    {
      "epoch": 2.6687392055267702,
      "grad_norm": 1.332458734512329,
      "learning_rate": 2.2872340425531916e-06,
      "loss": 0.7996,
      "step": 4830
    },
    {
      "epoch": 2.67426597582038,
      "grad_norm": 1.3638702630996704,
      "learning_rate": 2.2492401215805472e-06,
      "loss": 0.8758,
      "step": 4840
    },
    {
      "epoch": 2.6797927461139897,
      "grad_norm": 1.4009407758712769,
      "learning_rate": 2.211246200607903e-06,
      "loss": 0.871,
      "step": 4850
    },
    {
      "epoch": 2.685319516407599,
      "grad_norm": 1.5677406787872314,
      "learning_rate": 2.1732522796352584e-06,
      "loss": 0.8623,
      "step": 4860
    },
    {
      "epoch": 2.690846286701209,
      "grad_norm": 1.2567384243011475,
      "learning_rate": 2.135258358662614e-06,
      "loss": 0.7886,
      "step": 4870
    },
    {
      "epoch": 2.6963730569948186,
      "grad_norm": 1.5087071657180786,
      "learning_rate": 2.0972644376899696e-06,
      "loss": 0.8183,
      "step": 4880
    },
    {
      "epoch": 2.7018998272884285,
      "grad_norm": 1.424385666847229,
      "learning_rate": 2.0592705167173256e-06,
      "loss": 0.836,
      "step": 4890
    },
    {
      "epoch": 2.707426597582038,
      "grad_norm": 1.3765712976455688,
      "learning_rate": 2.021276595744681e-06,
      "loss": 0.8029,
      "step": 4900
    },
    {
      "epoch": 2.707426597582038,
      "eval_loss": 0.8513681292533875,
      "eval_runtime": 390.0684,
      "eval_samples_per_second": 4.125,
      "eval_steps_per_second": 0.518,
      "step": 4900
    },
    {
      "epoch": 2.712953367875648,
      "grad_norm": 1.6426092386245728,
      "learning_rate": 1.9832826747720364e-06,
      "loss": 0.8677,
      "step": 4910
    },
    {
      "epoch": 2.7184801381692574,
      "grad_norm": 1.4559043645858765,
      "learning_rate": 1.9452887537993924e-06,
      "loss": 0.8223,
      "step": 4920
    },
    {
      "epoch": 2.724006908462867,
      "grad_norm": 1.5076652765274048,
      "learning_rate": 1.907294832826748e-06,
      "loss": 0.8391,
      "step": 4930
    },
    {
      "epoch": 2.729533678756477,
      "grad_norm": 1.3856652975082397,
      "learning_rate": 1.8693009118541036e-06,
      "loss": 0.8118,
      "step": 4940
    },
    {
      "epoch": 2.7350604490500863,
      "grad_norm": 1.5196226835250854,
      "learning_rate": 1.831306990881459e-06,
      "loss": 0.8408,
      "step": 4950
    },
    {
      "epoch": 2.7405872193436958,
      "grad_norm": 1.4304838180541992,
      "learning_rate": 1.7933130699088146e-06,
      "loss": 0.8509,
      "step": 4960
    },
    {
      "epoch": 2.7461139896373057,
      "grad_norm": 1.4483226537704468,
      "learning_rate": 1.7553191489361704e-06,
      "loss": 0.8254,
      "step": 4970
    },
    {
      "epoch": 2.7516407599309156,
      "grad_norm": 1.489714503288269,
      "learning_rate": 1.717325227963526e-06,
      "loss": 0.779,
      "step": 4980
    },
    {
      "epoch": 2.757167530224525,
      "grad_norm": 1.4590245485305786,
      "learning_rate": 1.6793313069908814e-06,
      "loss": 0.8475,
      "step": 4990
    },
    {
      "epoch": 2.7626943005181346,
      "grad_norm": 1.6126923561096191,
      "learning_rate": 1.6413373860182372e-06,
      "loss": 0.8715,
      "step": 5000
    },
    {
      "epoch": 2.7626943005181346,
      "eval_loss": 0.8510056138038635,
      "eval_runtime": 405.2526,
      "eval_samples_per_second": 3.97,
      "eval_steps_per_second": 0.498,
      "step": 5000
    },
    {
      "epoch": 2.7682210708117445,
      "grad_norm": 1.3000003099441528,
      "learning_rate": 1.6033434650455928e-06,
      "loss": 0.8455,
      "step": 5010
    },
    {
      "epoch": 2.773747841105354,
      "grad_norm": 1.4410210847854614,
      "learning_rate": 1.5653495440729486e-06,
      "loss": 0.8021,
      "step": 5020
    },
    {
      "epoch": 2.7792746113989635,
      "grad_norm": 2.1059844493865967,
      "learning_rate": 1.527355623100304e-06,
      "loss": 0.8925,
      "step": 5030
    },
    {
      "epoch": 2.7848013816925734,
      "grad_norm": 1.3789278268814087,
      "learning_rate": 1.4893617021276596e-06,
      "loss": 0.8174,
      "step": 5040
    },
    {
      "epoch": 2.7903281519861833,
      "grad_norm": 1.4796329736709595,
      "learning_rate": 1.4513677811550154e-06,
      "loss": 0.8907,
      "step": 5050
    },
    {
      "epoch": 2.795854922279793,
      "grad_norm": 1.3299952745437622,
      "learning_rate": 1.413373860182371e-06,
      "loss": 0.8337,
      "step": 5060
    },
    {
      "epoch": 2.8013816925734023,
      "grad_norm": 1.3553966283798218,
      "learning_rate": 1.3753799392097266e-06,
      "loss": 0.9181,
      "step": 5070
    },
    {
      "epoch": 2.8069084628670122,
      "grad_norm": 1.3351521492004395,
      "learning_rate": 1.3373860182370822e-06,
      "loss": 0.796,
      "step": 5080
    },
    {
      "epoch": 2.8124352331606217,
      "grad_norm": 1.3454917669296265,
      "learning_rate": 1.2993920972644378e-06,
      "loss": 0.7877,
      "step": 5090
    },
    {
      "epoch": 2.817962003454231,
      "grad_norm": 1.4198050498962402,
      "learning_rate": 1.2613981762917934e-06,
      "loss": 0.8358,
      "step": 5100
    },
    {
      "epoch": 2.817962003454231,
      "eval_loss": 0.850662350654602,
      "eval_runtime": 404.3366,
      "eval_samples_per_second": 3.979,
      "eval_steps_per_second": 0.5,
      "step": 5100
    },
    {
      "epoch": 2.823488773747841,
      "grad_norm": 1.5711125135421753,
      "learning_rate": 1.223404255319149e-06,
      "loss": 0.8348,
      "step": 5110
    },
    {
      "epoch": 2.8290155440414506,
      "grad_norm": 1.4627964496612549,
      "learning_rate": 1.1854103343465048e-06,
      "loss": 0.8312,
      "step": 5120
    },
    {
      "epoch": 2.8345423143350605,
      "grad_norm": 1.3645211458206177,
      "learning_rate": 1.1474164133738602e-06,
      "loss": 0.8307,
      "step": 5130
    },
    {
      "epoch": 2.84006908462867,
      "grad_norm": 1.421101689338684,
      "learning_rate": 1.109422492401216e-06,
      "loss": 0.8114,
      "step": 5140
    },
    {
      "epoch": 2.84559585492228,
      "grad_norm": 1.5755099058151245,
      "learning_rate": 1.0714285714285714e-06,
      "loss": 0.8445,
      "step": 5150
    },
    {
      "epoch": 2.8511226252158894,
      "grad_norm": 1.2452983856201172,
      "learning_rate": 1.0334346504559272e-06,
      "loss": 0.8447,
      "step": 5160
    },
    {
      "epoch": 2.856649395509499,
      "grad_norm": 1.4491807222366333,
      "learning_rate": 9.954407294832828e-07,
      "loss": 0.837,
      "step": 5170
    },
    {
      "epoch": 2.862176165803109,
      "grad_norm": 1.4366306066513062,
      "learning_rate": 9.574468085106384e-07,
      "loss": 0.9374,
      "step": 5180
    },
    {
      "epoch": 2.8677029360967183,
      "grad_norm": 1.3455798625946045,
      "learning_rate": 9.194528875379941e-07,
      "loss": 0.7818,
      "step": 5190
    },
    {
      "epoch": 2.8732297063903283,
      "grad_norm": 1.4647672176361084,
      "learning_rate": 8.814589665653496e-07,
      "loss": 0.8035,
      "step": 5200
    },
    {
      "epoch": 2.8732297063903283,
      "eval_loss": 0.8505079746246338,
      "eval_runtime": 387.9361,
      "eval_samples_per_second": 4.148,
      "eval_steps_per_second": 0.521,
      "step": 5200
    },
    {
      "epoch": 2.8787564766839377,
      "grad_norm": 1.5077325105667114,
      "learning_rate": 8.434650455927053e-07,
      "loss": 0.8646,
      "step": 5210
    },
    {
      "epoch": 2.8842832469775477,
      "grad_norm": 1.4626089334487915,
      "learning_rate": 8.054711246200609e-07,
      "loss": 0.8283,
      "step": 5220
    },
    {
      "epoch": 2.889810017271157,
      "grad_norm": 1.470992922782898,
      "learning_rate": 7.674772036474166e-07,
      "loss": 0.846,
      "step": 5230
    },
    {
      "epoch": 2.8953367875647666,
      "grad_norm": 1.4495505094528198,
      "learning_rate": 7.294832826747721e-07,
      "loss": 0.8829,
      "step": 5240
    },
    {
      "epoch": 2.9008635578583766,
      "grad_norm": 1.4997550249099731,
      "learning_rate": 6.914893617021278e-07,
      "loss": 0.8842,
      "step": 5250
    },
    {
      "epoch": 2.906390328151986,
      "grad_norm": 1.4839112758636475,
      "learning_rate": 6.534954407294832e-07,
      "loss": 0.8305,
      "step": 5260
    },
    {
      "epoch": 2.911917098445596,
      "grad_norm": 1.6134661436080933,
      "learning_rate": 6.15501519756839e-07,
      "loss": 0.8259,
      "step": 5270
    },
    {
      "epoch": 2.9174438687392055,
      "grad_norm": 1.608766794204712,
      "learning_rate": 5.775075987841945e-07,
      "loss": 0.8355,
      "step": 5280
    },
    {
      "epoch": 2.9229706390328154,
      "grad_norm": 1.3410346508026123,
      "learning_rate": 5.395136778115502e-07,
      "loss": 0.8064,
      "step": 5290
    },
    {
      "epoch": 2.928497409326425,
      "grad_norm": 1.632448673248291,
      "learning_rate": 5.015197568389058e-07,
      "loss": 0.8135,
      "step": 5300
    },
    {
      "epoch": 2.928497409326425,
      "eval_loss": 0.8502200841903687,
      "eval_runtime": 391.0488,
      "eval_samples_per_second": 4.115,
      "eval_steps_per_second": 0.517,
      "step": 5300
    },
    {
      "epoch": 2.9340241796200344,
      "grad_norm": 1.3504499197006226,
      "learning_rate": 4.6352583586626144e-07,
      "loss": 0.8482,
      "step": 5310
    },
    {
      "epoch": 2.9395509499136443,
      "grad_norm": 1.876363754272461,
      "learning_rate": 4.2553191489361704e-07,
      "loss": 0.8055,
      "step": 5320
    },
    {
      "epoch": 2.945077720207254,
      "grad_norm": 1.3898321390151978,
      "learning_rate": 3.8753799392097264e-07,
      "loss": 0.8307,
      "step": 5330
    },
    {
      "epoch": 2.9506044905008637,
      "grad_norm": 1.4183999300003052,
      "learning_rate": 3.495440729483283e-07,
      "loss": 0.8942,
      "step": 5340
    },
    {
      "epoch": 2.956131260794473,
      "grad_norm": 1.4150822162628174,
      "learning_rate": 3.1155015197568394e-07,
      "loss": 0.7917,
      "step": 5350
    },
    {
      "epoch": 2.961658031088083,
      "grad_norm": 1.5748742818832397,
      "learning_rate": 2.7355623100303953e-07,
      "loss": 0.8376,
      "step": 5360
    },
    {
      "epoch": 2.9671848013816926,
      "grad_norm": 1.745856523513794,
      "learning_rate": 2.3556231003039516e-07,
      "loss": 0.8458,
      "step": 5370
    },
    {
      "epoch": 2.972711571675302,
      "grad_norm": 1.4656517505645752,
      "learning_rate": 1.9756838905775078e-07,
      "loss": 0.8254,
      "step": 5380
    },
    {
      "epoch": 2.978238341968912,
      "grad_norm": 1.580344796180725,
      "learning_rate": 1.5957446808510638e-07,
      "loss": 0.8155,
      "step": 5390
    },
    {
      "epoch": 2.9837651122625215,
      "grad_norm": 1.4538244009017944,
      "learning_rate": 1.2158054711246203e-07,
      "loss": 0.8221,
      "step": 5400
    },
    {
      "epoch": 2.9837651122625215,
      "eval_loss": 0.8503841161727905,
      "eval_runtime": 393.7744,
      "eval_samples_per_second": 4.086,
      "eval_steps_per_second": 0.513,
      "step": 5400
    }
  ],
  "logging_steps": 10,
  "max_steps": 5427,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.7459917265698816e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
